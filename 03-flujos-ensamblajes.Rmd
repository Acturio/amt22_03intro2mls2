<div class="watermark"><img src="img/header.png" width="400"></div>

# Workflowsets

Es común no sepamos ni remotamente cuál es el mejor modelo que podríamos implementar al iniciar un proyecto con datos que nunca antes hemos visto. Es posible que un profesional de datos deba seleccionar muchas combinaciones de modelos y preprocesadores. También es posible tener poco o ningún conocimiento a priori sobre qué método funcionará mejor con un nuevo conjunto de datos.

> Una buena estrategia es dedicar un esfuerzo inicial a probar una variedad de enfoques de modelado, determinar qué funciona mejor y luego invertir tiempo adicional ajustando / optimizando un pequeño conjunto de modelos.

## Múltiples recetas

Algunos modelos requieren predictores que se han centrado y escalado, por lo que algunos flujos de trabajo de modelos requerirán recetas con estos pasos de preprocesamiento. Para otros modelos, crear interacciones cuadráticas y bidireccionales. Para estos fines, creamos múltiples recetas:

```{r}
library(tidymodels)

data(ames)

set.seed(4595)
ames_split <- initial_split(ames, prop = 0.75)
ames_train <- training(ames_split)
ames_test  <- testing(ames_split)
ames_folds <- vfold_cv(ames_train)
```

* **Receta Original**

```{r}
receta_original <- recipe(Sale_Price ~ . , data = ames_train) %>%
  step_unknown(Alley) %>%
  step_rename(Year_Remod = Year_Remod_Add) %>% 
  step_rename(ThirdSsn_Porch = Three_season_porch) %>% 
  step_ratio(Bedroom_AbvGr, denom = denom_vars(Gr_Liv_Area)) %>% 
  step_mutate(
    Age_House = Year_Sold - Year_Remod,
    TotalSF   = Gr_Liv_Area + Total_Bsmt_SF,
    AvgRoomSF   = Gr_Liv_Area / TotRms_AbvGrd,
    Pool = if_else(Pool_Area > 0, 1, 0),
    Exter_Cond = forcats::fct_collapse(Exter_Cond, Good = c("Typical", "Good", "Excellent"))) %>% 
  step_relevel(Exter_Cond, ref_level = "Good") %>% 
  step_normalize(all_predictors(), -all_nominal()) %>%
  step_dummy(all_nominal()) %>% 
  step_interact(~ Second_Flr_SF:First_Flr_SF) %>% 
  step_interact(~ matches("Bsmt_Cond"):TotRms_AbvGrd) %>% 
  step_rm(
    First_Flr_SF, Second_Flr_SF, Year_Remod,
    Bsmt_Full_Bath, Bsmt_Half_Bath, 
    Kitchen_AbvGr, BsmtFin_Type_1_Unf, 
    Total_Bsmt_SF, Kitchen_AbvGr, Pool_Area, 
    Gr_Liv_Area, Sale_Type_Oth, Sale_Type_VWD
  ) 

receta_original_prep <- receta_original %>% prep()
```

* **Receta PCA:**

```{r}
receta_knn <- recipe(Sale_Price ~ . , data = ames_train) %>%
  step_unknown(Alley) %>%
  step_unknown(Pool_QC) %>%
  step_unknown(Misc_Feature) %>%
  step_unknown(Fence) %>%
  step_unknown(Garage_Finish) %>%
  step_unknown(Garage_Cond) %>%
  step_unknown(Garage_Type) %>%
  step_unknown(Bsmt_Exposure) %>%
  step_unknown(Bsmt_Cond) %>%
  step_unknown(BsmtFin_Type_1) %>%
  step_unknown(BsmtFin_Type_2) %>%
  step_unknown(Mas_Vnr_Type) %>%
  step_unknown(Electrical) %>%
  step_impute_knn(
    Mas_Vnr_Area, Lot_Frontage, 
    impute_with= all_predictors(),
    neighbors = 5) %>%
  step_rename(Year_Remod = Year_Remod_Add) %>% 
  step_rename(ThirdSsn_Porch = Three_season_porch) %>% 
  step_ratio(Bedroom_AbvGr, denom = denom_vars(Gr_Liv_Area)) %>% 
  step_mutate(
    Age_House = Year_Sold - Year_Remod,
    TotalSF   = Gr_Liv_Area + Total_Bsmt_SF,
    AvgRoomSF   = Gr_Liv_Area / TotRms_AbvGrd,
    Pool = if_else(Pool_Area > 0, 1, 0),
    Exter_Cond = forcats::fct_collapse(Exter_Cond, Good = c("Typical", "Good", "Excellent"))) %>% 
  step_relevel(Exter_Cond, ref_level = "Good") %>% 
  step_normalize(all_predictors(), -all_nominal()) %>%
  step_dummy(all_nominal()) %>% 
  step_interact(~ Second_Flr_SF:First_Flr_SF) %>% 
  step_interact(~ matches("Bsmt_Cond"):TotRms_AbvGrd) 

receta_knn_prep <- receta_knn %>% prep()
```

* **Receta Grande:**

```{r}
receta_grande <- recipe(Sale_Price ~ . , data = ames_train) %>%
  step_unknown(Alley) %>%
  step_unknown(Fence) %>%
  step_unknown(Garage_Type) %>%
  step_unknown(Garage_Finish) %>%
  step_unknown(Garage_Cond) %>%
  step_unknown(Bsmt_Cond) %>%
  step_unknown(Bsmt_Exposure) %>%
  step_unknown(BsmtFin_Type_1) %>%
  step_unknown(BsmtFin_Type_2) %>%
  step_unknown(Mas_Vnr_Type) %>%
  step_unknown(Electrical) %>%
  step_unknown(Heating_QC) %>%
  step_unknown(Pool_QC) %>% 
  step_rename(Year_Remod = Year_Remod_Add) %>% 
  step_rename(ThirdSsn_Porch = Three_season_porch) %>% 
  step_ratio(Bedroom_AbvGr, denom = denom_vars(Gr_Liv_Area)) %>% 
  step_ratio(Second_Flr_SF, denom = denom_vars(First_Flr_SF)) %>% 
  step_mutate(
    TotalBaths = Full_Bath + Bsmt_Full_Bath + 0.5 * (Half_Bath + Bsmt_Half_Bath),
    Age_House = Year_Sold - Year_Remod,
    TotalSF = Gr_Liv_Area + Total_Bsmt_SF,
    AvgRoomSF = Gr_Liv_Area / TotRms_AbvGrd,
    Porch_SF = Enclosed_Porch + ThirdSsn_Porch + Open_Porch_SF,
    Porch = factor(Porch_SF > 0),
    Pool = if_else(Pool_Area > 0,1,0),
    Exter_Cond = forcats::fct_collapse(Exter_Cond, Good = c("Typical", "Good", "Excellent")),
    Condition_1 = forcats::fct_collapse(
      Condition_1, 
      Artery_Feedr = c("Feedr", "Artery"), 
      Railr = c("RRAn", "RRNn", "RRNe", "RRAe"),
      Norm = "Norm",
      Pos = c("PosN", "PosA")), 
    Land_Slope = forcats::fct_collapse(Land_Slope, Mod_Sev = c("Mod", "Sev")),
    Land_Contour = forcats::fct_collapse(Land_Contour, Low_HLS = c("Low","HLS"), Bnk_Lvl = c("Lvl","Bnk")),
    Lot_Shape = forcats::fct_collapse(Lot_Shape, IRREG = c("Slightly_Irregular", "Moderately_Irregular", "Irregular")),
    Bsmt_Cond = forcats::fct_collapse(Bsmt_Cond, Exc = c("Good", "Excellent")),
    BsmtFin_Type_1 = forcats::fct_collapse(BsmtFin_Type_1, Rec_BLQ = c("Rec", "BLQ")),
    BsmtFin_Type_2 = forcats::fct_collapse(BsmtFin_Type_2, Rec_BLQ = c("Rec", "BLQ","LwQ")),
    Neighborhood = forcats::fct_collapse(
      Neighborhood, 
      NoRidge_GrnHill = c("Northridge", "Green_Hills"),
      Crawfor_Greens = c("Crawford", "Greens"),
      Blueste_Mitchel = c("Blueste", "Mitchell"),
      Blmngtn_CollgCr = c("Bloomington_Heights", "College_Creek"),
      NPkVill_NAmes = c("Northpark_Villa", "North_Ames"),
      Veenker_StoneBr = c("Veenker", "Stone_Brook"),
      BrDale_IDOTRR = c("Briardale", "Iowa_DOT_and_Rail_Road"),
      SWISU_Sawyer = c("South_and_West_of_Iowa_State_University", "Sawyer"),
      ClearCr_Somerst = c("Clear_Creek", "Somerset")),
    Heating = forcats::fct_collapse(
      Heating, Grav_Wall = c("Grav", "Wall"),
      GasA_W = c("GasA", "GasW", "OthW")),
    MS_Zoning = forcats::fct_collapse(
      MS_Zoning, I_R_M_H = c("Residential_Medium_Density", "I_all", "Residential_High_Density" )),
    Bldg_Type = forcats::fct_collapse(Bldg_Type, Du_Tu = c("Duplex", "Twnhs")),
    Foundation = forcats::fct_collapse(Foundation, Wood_Stone = c("Wood", "Stone")),
    Functional = forcats::fct_collapse(
      Functional, Min = c("Min1", "Min2"), Maj = c("Maj1", "Maj2", "Mod"))) %>% 
  step_relevel(Exter_Cond, ref_level = "Good") %>% 
  step_relevel(Condition_1, ref_level = "Norm") %>%
  step_normalize(all_predictors(), -all_nominal()) %>%
  step_dummy(all_nominal()) %>% 
  step_interact(~ Second_Flr_SF:Bedroom_AbvGr) %>%
  step_interact(~ TotalSF:TotRms_AbvGrd) %>%
  step_interact(~ Age_House:TotRms_AbvGrd) %>%
  step_interact(~ Second_Flr_SF:First_Flr_SF) %>% 
  step_interact(~ matches("Bsmt_Cond"):TotRms_AbvGrd) %>% 
  step_interact(~ matches("BsmtFin_Type_1"):BsmtFin_SF_1) %>% 
  step_interact(~ matches("BsmtFin_Type_1"):Total_Bsmt_SF) %>% 
  step_interact(~ matches("Heating_QC"):TotRms_AbvGrd) %>% 
  step_interact(~ matches("Heating_QC"):TotalSF) %>%
  step_interact(~ matches("Heating_QC"):Second_Flr_SF) %>%
  step_interact(~ matches("Neighborhood"):matches("Condition_1")) %>% 
  step_rm(
    First_Flr_SF, Second_Flr_SF, Year_Remod,
    Bsmt_Full_Bath, Bsmt_Half_Bath, 
    Kitchen_AbvGr, BsmtFin_Type_1_Unf, 
    Total_Bsmt_SF, Kitchen_AbvGr, Pool_Area, 
    Gr_Liv_Area, Porch_SF,
    Sale_Type_Oth, Sale_Type_VWD
  )

receta_grande_prep <- receta_grande %>% prep()
```

## Múltiples modelos

Una vez que tenemos suficientes recetas, podemos experimentar con múltiples modelos para poner a prueba. Usaremos los modelos que hemos aprendido a implementar en todo el curso:

```{r}
library(rules)
library(baguette)
library(tune)

elasticnet_model <- linear_reg(
  mode = "regression",
  penalty = tune(),
  mixture = tune()) %>%
  set_engine("glmnet") 

knn_model <- nearest_neighbor(
  mode = "regression",
  neighbors = tune("K"),
  dist_power = tune(),
  weight_func = tune()) %>%
  set_engine("kknn")

rforest_model <- rand_forest(
  mode = "regression",
  trees = 1000,
  mtry = tune(),
  min_n = tune()) %>%
  set_engine(
    "ranger",
    importance = "impurity"
  )

svm_rbf_model <- svm_rbf(
  cost = tune(),
  rbf_sigma = tune(),
  margin = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("regression")

xgboost_model <- boost_tree(
  mode = "regression",
  trees = 1000,
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune(),
  learn_rate = tune()) %>%
  set_engine(
    "xgboost",
    importance = "impurity"
  )

```

**¿Cómo podemos hacer coincidir estos modelos con las recetas desarrolladas, ajustarlos y luego evaluar su rendimiento de manera eficiente? WORKFLOWSETS ofrece una solución.**


## Creación de workflowset

Los conjuntos de flujo de trabajo toman listas nombradas de preprocesadores y especificaciones de modelos y las combinan en un objeto que contiene múltiples flujos de trabajo. 

Como primer ejemplo de conjunto de flujo de trabajo, combinemos las recetas creadas en la sección anterior.

```{r}
workflow_set_models <- workflow_set(
  preproc = list(
    receta_original = receta_original_prep, 
    receta_knn = receta_knn_prep,
    receta_grande = receta_grande_prep
    ),
  models = list(
    elasticnet = elasticnet_model,
    knn = knn_model,
    rf = rforest_model,
    svm_rbf = svm_rbf_model,
    boost = xgboost_model
    )
  )

workflow_set_models
```

Dado que el preprocesador contiene más de una entrada, la función crea todas las combinaciones de preprocesadores y modelos.

* **info:** Contiene un *tibble* con algunos identificadores y el objeto de flujo de trabajo. 

* **option:** Es un marcador de posición para cualquier argumento que se utilice cuando evaluamos el flujo de trabajo. 

* **result:** Es un marcador de posición para la salida de las funciones de ajuste o remuestreo.


## Ajuste y evaluación de modelos

Casi todos estos flujos de trabajo contienen parámetros de ajuste. Para evaluar su rendimiento, podemos utilizar las funciones estándar de ajuste o remuestreo (por ejemplo, `tune_grid()`).

La función `workflow_map()` aplicará la misma función a todos los flujos de trabajo del conjunto; el valor predeterminado es `tune_grid()`.

A continuación se declaran los parámetros para cada modelo y el grid:

```{r, warning=FALSE, message=FALSE}

elasticnet_params <- elasticnet_model %>%
  parameters() %>%
  update(
    penalty = penalty(
      range = c(-2, 3),
      trans = log10_trans()),
    mixture = dials::mixture(range = c(0, 1))
  )

knn_params <- knn_model %>%
  parameters() %>%
  update(
    K = dials::neighbors(c(5, 80)),
    dist_power = dist_power(range = c(1, 3)),
    weight_func = weight_func(values = c("rectangular", "inv", "gaussian", "cos"))
  )

rforest_params <- rforest_model %>%
  parameters() %>%
  update(
    mtry = mtry(range = c(15, 150)),
    min_n = min_n(range = c(3,15))
  )

svm_rbf_params <- svm_rbf_model %>%
  parameters() %>%
  update(
    cost = cost(c(0, 0.5)),
    rbf_sigma = rbf_sigma(c(-3, 3)),
    margin = svm_margin(c(-2, 2))
  )

xgboost_params <- xgboost_model %>%
  parameters() %>%
  update(
    min_n = min_n(range = c(5,15)),
    mtry = mtry(range = c(15, 150)),
    tree_depth = tree_depth(range = c(3, 50)),
    loss_reduction = loss_reduction(range = c(-10, 1.5), trans = log10_trans()),
    learn_rate = learn_rate(range = c(-6, -0.25), trans = log10_trans()),
    sample_size = sample_prop()
  )

# Declaración del grid
workflow_tunning_set_models <- workflow_set_models %>%
  option_add(param_info = elasticnet_params, id = "elasticnet") %>% 
  option_add(param_info = knn_params, id = "knn") %>%
  option_add(param_info = rforest_params, id = "rf") %>%
  option_add(param_info = svm_rbf_params, id = "svm_rbf") %>%
  option_add(param_info = xgboost_params, id = "xgboost")

workflow_tunning_set_models
```

Para este ejemplo, la búsqueda del *grid* se aplica al flujo de trabajo.

```{r, message=TRUE, eval=FALSE}
library(doParallel)

UseCores <- detectCores() - 1
cluster <- makeCluster(UseCores)
registerDoParallel(cluster)

grid_ctrl <- control_grid(
    save_pred = TRUE,
    save_workflow = TRUE,
    parallel_over = "everything"
)

set.seed(536)
tunning_models_result <- workflow_tunning_set_models %>%
  workflow_map(
    fn = "tune_grid",
    seed = 20220603,
    resamples = ames_folds,
    grid = 100,
    metrics =  metric_set(rmse, mae, mape, rsq),
    control = grid_ctrl,
    verbose = TRUE
  )

stopCluster(cluster)

tunning_models_result %>% saveRDS("models/ensemble_model_test.rds")

```

```{r}
tunning_models_result <- readRDS("models/ensemble_model.rds")

tunning_models_result$result 
```

```{r}

```



```{r}
tunning_models_result %>% 
  extract_workflow_set_result("receta_knn_elasticnet") %>% 
  collect_notes() %>% 
  pull(note) %>% .[1]
```


```{r}
autoplot(
  tunning_models_result %>% filter(wflow_id != "receta_knn_elasticnet"),
  rank_metric = "rsq",
  metric = "rsq",   
  select_best = F) +   
  lims(y = c(0, 1)) +
  ggtitle("Model Comparisson")
```

```{r}
autoplot(
  tunning_models_result %>% filter(wflow_id != "receta_knn_elasticnet"),
  rank_metric = "rsq",
  metric = "rsq",   
  select_best = T) +
  geom_text(aes(y = mean - 0.10 , label = wflow_id), angle = 90, hjust = 1) +
  lims(y = c(0, 1)) +
  ggtitle("Model Comparisson")
```
































