<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 3 Support Vector Machine (SVM / SVR) | AMAT- Ciencia de Datos y Machine Learning 2</title>
  <meta name="description" content="AMAT Curso 2 : Ciencia de Datos y Machine Learning 2" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 3 Support Vector Machine (SVM / SVR) | AMAT- Ciencia de Datos y Machine Learning 2" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="AMAT Curso 2 : Ciencia de Datos y Machine Learning 2" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 3 Support Vector Machine (SVM / SVR) | AMAT- Ciencia de Datos y Machine Learning 2" />
  
  <meta name="twitter:description" content="AMAT Curso 2 : Ciencia de Datos y Machine Learning 2" />
  

<meta name="author" content="Karina Lizette Gamboa Puente" />
<meta name="author" content="Oscar Arturo Bringas López" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="feature-engineering.html"/>
<link rel="next" href="bagging-boosting.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li|
|:-:|  
<center>Ciencia de Datos y Machine Learning 2</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructores"><i class="fa fa-check"></i>Instructores</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ciencia-de-datos-en-r"><i class="fa fa-check"></i>Ciencia de Datos en R</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#estructura-del-curso-actual"><i class="fa fa-check"></i>Estructura del curso actual</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-curso"><i class="fa fa-check"></i>Alcances del curso</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duración-y-evaluación-del-curso"><i class="fa fa-check"></i>Duración y evaluación del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-dinámica-de-clase"><i class="fa fa-check"></i>Recursos y dinámica de clase</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="repaso.html"><a href="repaso.html"><i class="fa fa-check"></i><b>1</b> Repaso</a>
<ul>
<li class="chapter" data-level="1.1" data-path="repaso.html"><a href="repaso.html#machine-learning"><i class="fa fa-check"></i><b>1.1</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2" data-path="repaso.html"><a href="repaso.html#tipos-de-aprendizaje"><i class="fa fa-check"></i><b>1.2</b> Tipos de aprendizaje</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="repaso.html"><a href="repaso.html#aprendizaje-supervisado"><i class="fa fa-check"></i><b>1.2.1</b> Aprendizaje supervisado</a></li>
<li class="chapter" data-level="1.2.2" data-path="repaso.html"><a href="repaso.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>1.2.2</b> Aprendizaje no supervisado</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="repaso.html"><a href="repaso.html#errores-sesgo-vs-varianza"><i class="fa fa-check"></i><b>1.3</b> Errores: Sesgo vs varianza</a></li>
<li class="chapter" data-level="1.4" data-path="repaso.html"><a href="repaso.html#partición-de-datos"><i class="fa fa-check"></i><b>1.4</b> Partición de datos</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="repaso.html"><a href="repaso.html#métodos-comunes-para-particionar-datos"><i class="fa fa-check"></i><b>1.4.1</b> Métodos comunes para particionar datos</a></li>
<li class="chapter" data-level="1.4.2" data-path="repaso.html"><a href="repaso.html#conjunto-de-validación"><i class="fa fa-check"></i><b>1.4.2</b> Conjunto de validación</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="repaso.html"><a href="repaso.html#recetas-y-tratamiento-de-datos"><i class="fa fa-check"></i><b>1.5</b> Recetas y tratamiento de datos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="repaso.html"><a href="repaso.html#pre-procesamiento-de-datos"><i class="fa fa-check"></i><b>1.5.1</b> Pre-procesamiento de datos</a></li>
<li class="chapter" data-level="1.5.2" data-path="repaso.html"><a href="repaso.html#recetas"><i class="fa fa-check"></i><b>1.5.2</b> Recetas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="feature-engineering.html"><a href="feature-engineering.html"><i class="fa fa-check"></i><b>2</b> Feature Engineering</a>
<ul>
<li class="chapter" data-level="2.1" data-path="feature-engineering.html"><a href="feature-engineering.html#regresión-polinomial"><i class="fa fa-check"></i><b>2.1</b> Regresión polinomial</a></li>
<li class="chapter" data-level="2.2" data-path="feature-engineering.html"><a href="feature-engineering.html#análisis-de-componentes-principales"><i class="fa fa-check"></i><b>2.2</b> Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="feature-engineering.html"><a href="feature-engineering.html#eigenvalores-y-eigenvectores"><i class="fa fa-check"></i><b>2.2.1</b> Eigenvalores y eigenvectores</a></li>
<li class="chapter" data-level="2.2.2" data-path="feature-engineering.html"><a href="feature-engineering.html#implementación-en-r"><i class="fa fa-check"></i><b>2.2.2</b> Implementación en R</a></li>
<li class="chapter" data-level="2.2.3" data-path="feature-engineering.html"><a href="feature-engineering.html#representación-gráfica"><i class="fa fa-check"></i><b>2.2.3</b> Representación gráfica</a></li>
<li class="chapter" data-level="2.2.4" data-path="feature-engineering.html"><a href="feature-engineering.html#cuántas-componentes-retener"><i class="fa fa-check"></i><b>2.2.4</b> ¿Cuántas componentes retener?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="feature-engineering.html"><a href="feature-engineering.html#imputación-knn"><i class="fa fa-check"></i><b>2.3</b> Imputación KNN</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="feature-engineering.html"><a href="feature-engineering.html#ventajas-y-limitaciones-del-clasificador-knn"><i class="fa fa-check"></i><b>2.3.1</b> <strong>Ventajas y limitaciones del Clasificador KNN</strong></a></li>
<li class="chapter" data-level="2.3.2" data-path="feature-engineering.html"><a href="feature-engineering.html#implementación-en-r-1"><i class="fa fa-check"></i><b>2.3.2</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="feature-engineering.html"><a href="feature-engineering.html#ejercicios"><i class="fa fa-check"></i><b>2.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html"><i class="fa fa-check"></i><b>3</b> Support Vector Machine (SVM / SVR)</a>
<ul>
<li class="chapter" data-level="3.1" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#maximum-margin-classifier"><i class="fa fa-check"></i><b>3.1</b> Maximum Margin Classifier</a></li>
<li class="chapter" data-level="3.2" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#support-vector-classifiers"><i class="fa fa-check"></i><b>3.2</b> Support Vector Classifiers</a></li>
<li class="chapter" data-level="3.3" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#support-vector-machine"><i class="fa fa-check"></i><b>3.3</b> Support Vector Machine</a></li>
<li class="chapter" data-level="3.4" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#el-truco-del-kernel"><i class="fa fa-check"></i><b>3.4</b> El truco del Kernel</a></li>
<li class="chapter" data-level="3.5" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#support-vector-regression"><i class="fa fa-check"></i><b>3.5</b> Support Vector Regression</a></li>
<li class="chapter" data-level="3.6" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#ventajas-y-desventajas"><i class="fa fa-check"></i><b>3.6</b> Ventajas y desventajas</a></li>
<li class="chapter" data-level="3.7" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#ajuste-del-modelo-con-r"><i class="fa fa-check"></i><b>3.7</b> Ajuste del modelo con R</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#implementación-de-svr-en-r"><i class="fa fa-check"></i><b>3.7.1</b> Implementación de SVR en R</a></li>
<li class="chapter" data-level="3.7.2" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#implementación-de-svm-en-r"><i class="fa fa-check"></i><b>3.7.2</b> Implementación de SVM en R</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="support-vector-machine-svm-svr.html"><a href="support-vector-machine-svm-svr.html#ejercicios-1"><i class="fa fa-check"></i><b>3.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bagging-boosting.html"><a href="bagging-boosting.html"><i class="fa fa-check"></i><b>4</b> Bagging &amp; Boosting</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bagging-boosting.html"><a href="bagging-boosting.html#aprendizaje-conjunto"><i class="fa fa-check"></i><b>4.1</b> Aprendizaje conjunto</a></li>
<li class="chapter" data-level="4.2" data-path="bagging-boosting.html"><a href="bagging-boosting.html#bagging-vs.-boosting"><i class="fa fa-check"></i><b>4.2</b> Bagging vs. boosting</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="bagging-boosting.html"><a href="bagging-boosting.html#error-out-of-bag"><i class="fa fa-check"></i><b>4.2.1</b> Error Out-Of-Bag</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="bagging-boosting.html"><a href="bagging-boosting.html#algoritmo-bagging"><i class="fa fa-check"></i><b>4.3</b> Algoritmo Bagging</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="bagging-boosting.html"><a href="bagging-boosting.html#ventajas-y-desventajas-de-bagging"><i class="fa fa-check"></i><b>4.3.1</b> Ventajas y desventajas de bagging</a></li>
<li class="chapter" data-level="4.3.2" data-path="bagging-boosting.html"><a href="bagging-boosting.html#aplicaciónes-de-bagging"><i class="fa fa-check"></i><b>4.3.2</b> Aplicaciónes de Bagging</a></li>
<li class="chapter" data-level="4.3.3" data-path="bagging-boosting.html"><a href="bagging-boosting.html#implementación-en-r-2"><i class="fa fa-check"></i><b>4.3.3</b> Implementación en <em>R</em></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="bagging-boosting.html"><a href="bagging-boosting.html#algoritmo-boosting"><i class="fa fa-check"></i><b>4.4</b> Algoritmo Boosting</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="bagging-boosting.html"><a href="bagging-boosting.html#predicciones-de-boosting"><i class="fa fa-check"></i><b>4.4.1</b> Predicciones de <em>Boosting</em></a></li>
<li class="chapter" data-level="4.4.2" data-path="bagging-boosting.html"><a href="bagging-boosting.html#modelos-boosting"><i class="fa fa-check"></i><b>4.4.2</b> Modelos <em>Boosting</em></a></li>
<li class="chapter" data-level="4.4.3" data-path="bagging-boosting.html"><a href="bagging-boosting.html#implementación-en-r-3"><i class="fa fa-check"></i><b>4.4.3</b> Implementación en R</a></li>
<li class="chapter" data-level="4.4.4" data-path="bagging-boosting.html"><a href="bagging-boosting.html#xgboost-para-regresión"><i class="fa fa-check"></i><b>4.4.4</b> XGBoost para regresión</a></li>
<li class="chapter" data-level="4.4.5" data-path="bagging-boosting.html"><a href="bagging-boosting.html#xgboost-para-clasificación"><i class="fa fa-check"></i><b>4.4.5</b> XGBoost para clasificación</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="bagging-boosting.html"><a href="bagging-boosting.html#ejercicios-2"><i class="fa fa-check"></i><b>4.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html"><i class="fa fa-check"></i><b>5</b> Workflowsets &amp; Stacking</a>
<ul>
<li class="chapter" data-level="5.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#múltiples-recetas"><i class="fa fa-check"></i><b>5.1</b> Múltiples recetas</a></li>
<li class="chapter" data-level="5.2" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#múltiples-modelos"><i class="fa fa-check"></i><b>5.2</b> Múltiples modelos</a></li>
<li class="chapter" data-level="5.3" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#creación-de-workflowset"><i class="fa fa-check"></i><b>5.3</b> Creación de workflowset</a></li>
<li class="chapter" data-level="5.4" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#ajuste-y-evaluación-de-modelos"><i class="fa fa-check"></i><b>5.4</b> Ajuste y evaluación de modelos</a></li>
<li class="chapter" data-level="5.5" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#extracción-de-modelos"><i class="fa fa-check"></i><b>5.5</b> Extracción de modelos</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#selección-de-modelo"><i class="fa fa-check"></i><b>5.5.1</b> Selección de modelo</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#métodos-de-carrera"><i class="fa fa-check"></i><b>5.6</b> Métodos de carrera</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#optimización-anova"><i class="fa fa-check"></i><b>5.6.1</b> Optimización ANOVA</a></li>
<li class="chapter" data-level="5.6.2" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#optimización-logística"><i class="fa fa-check"></i><b>5.6.2</b> Optimización Logística</a></li>
<li class="chapter" data-level="5.6.3" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#optimización-bayesiana"><i class="fa fa-check"></i><b>5.6.3</b> Optimización Bayesiana</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#stacking"><i class="fa fa-check"></i><b>5.7</b> Stacking</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#elección-de-modelos"><i class="fa fa-check"></i><b>5.7.1</b> Elección de modelos</a></li>
<li class="chapter" data-level="5.7.2" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#ajuste-final"><i class="fa fa-check"></i><b>5.7.2</b> Ajuste final</a></li>
<li class="chapter" data-level="5.7.3" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#comparación-de-métricas"><i class="fa fa-check"></i><b>5.7.3</b> Comparación de métricas</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#ejercicios-3"><i class="fa fa-check"></i><b>5.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html"><i class="fa fa-check"></i><b>6</b> Sesgo e Inequidad</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#propósito-vs-error"><i class="fa fa-check"></i><b>6.1</b> Propósito Vs Error</a></li>
<li class="chapter" data-level="6.2" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#métricas"><i class="fa fa-check"></i><b>6.2</b> Métricas</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#equal-parity-or-demographic-or-statistical-parity"><i class="fa fa-check"></i><b>6.2.1</b> Equal Parity or Demographic or Statistical Parity</a></li>
<li class="chapter" data-level="6.2.2" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#proportional-parity-o-impact-parity-o-minimizing-disparate-impact"><i class="fa fa-check"></i><b>6.2.2</b> Proportional Parity o Impact Parity o Minimizing Disparate Impact</a></li>
<li class="chapter" data-level="6.2.3" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#equalized-odds"><i class="fa fa-check"></i><b>6.2.3</b> Equalized odds</a></li>
<li class="chapter" data-level="6.2.4" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#predictive-rate-parity"><i class="fa fa-check"></i><b>6.2.4</b> Predictive rate parity</a></li>
<li class="chapter" data-level="6.2.5" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#accuracy-parity"><i class="fa fa-check"></i><b>6.2.5</b> Accuracy parity</a></li>
<li class="chapter" data-level="6.2.6" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#false-negative-parity-o-equal-oppportunity"><i class="fa fa-check"></i><b>6.2.6</b> False Negative Parity o Equal Oppportunity</a></li>
<li class="chapter" data-level="6.2.7" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#false-positive-parity"><i class="fa fa-check"></i><b>6.2.7</b> False Positive Parity</a></li>
<li class="chapter" data-level="6.2.8" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#negative-predictive-value-parity"><i class="fa fa-check"></i><b>6.2.8</b> Negative predictive value parity</a></li>
<li class="chapter" data-level="6.2.9" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#specificity-parity"><i class="fa fa-check"></i><b>6.2.9</b> Specificity parity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">AMAT- Ciencia de Datos y Machine Learning 2</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="support-vector-machine-svm-svr" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Capítulo 3</span> Support Vector Machine (SVM / SVR)<a href="support-vector-machine-svm-svr.html#support-vector-machine-svm-svr" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Es común encontrar en la literatura el nombre de SVM para referirse tanto al caso de regresión como al de clasificación, no obstante, SVR se refiere particularmente a <em>Suport Vector Regression</em>.</p>
<p>Support vector machine, llamado SVM, es un algoritmo de aprendizaje supervisado que se puede utilizar para problemas de clasificación y regresión. Se utiliza para conjuntos de datos más pequeños, ya que <strong>tarda demasiado en procesarse.</strong></p>
<p>El principal objetivo de esta técnica es encontrar el <strong>Hiperplano de Separación Óptima</strong>, también conocido como <em>Boundary Decision</em>, el cual será el margen de clasificación más grande que podamos ajustar para separar a las clases involucradas, limitando las veces que una observación viola dicho margen.</p>
<p><img src="img/02-svm/01_inseparable_classes.png" width="800pt" height="400pt" style="display: block; margin: auto;" /></p>
<p>Para entender este algoritmo es necesario entender 3 conceptos principales:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li><p>Maximum margin classifiers</p></li>
<li><p>Support vector classifiers</p></li>
<li><p>Support vector machines</p></li>
</ol>
</blockquote>
<p>Estudiemos cada uno de estos principios.</p>
<div id="maximum-margin-classifier" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Maximum Margin Classifier<a href="support-vector-machine-svm-svr.html#maximum-margin-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A menudo se generalizan con máquinas de vectores de soporte, pero SVM tiene muchos más parámetros en comparación. El <em>clasificador de margen máximo</em> considera un hiperplano con ancho de separación máxima para clasificar los datos. Sin embargo, se pueden dibujar infinitos hiperplanos en un conjunto de datos por lo que es importante <strong>elegir el hiperplano ideal para la clasificación.</strong></p>
<p>En un espacio <em>n-dimensional</em>, un hiperplano es un subespacio de la dimensión n-1. Es decir, si los datos tienen un espacio bidimensional, entonces el hiperplano puede ser una línea recta que divide el espacio de datos en dos mitades y pasa por la siguiente ecuacion:</p>
<p><span class="math display">\[\beta_0 + \beta_1X_1 + \beta_2X_2=0\]</span></p>
<p>Las observaciones que caen en el hiperplano sigue la ecuación anterior. Las observaciones que caen en la región por encima o por debajo del hiperplano sigue las siguientes ecuaciones:</p>
<p><span class="math display">\[\beta_0 + \beta_1X_1 + \beta_2X_2&gt;0\]</span></p>
<p><span class="math display">\[\beta_0 + \beta_1X_1 + \beta_2X_2&lt;0\]</span></p>
<p>El clasificador de margen máximo <strong>a menudo falla en la situación de casos no separables</strong> en los que no puede asignar un hiperplano diferente para clasificar datos no separables. Para tales casos, un clasificador de vectores de soporte viene al rescate.</p>
<p><img src="img/02-svm/02_maximum_margin_classifier.png" width="900pt" height="380pt" style="display: block; margin: auto;" /></p>
<p>Del diagrama anterior, podemos suponer infinitos hiperplanos (izquierda). El clasificador de margen máximo viene con un solo hiperplano que divide los datos como en la gráfica de la derecha. <strong>Los datos que tocan los hiperplanos positivo y negativo se denominan vectores de soporte</strong>.</p>
</div>
<div id="support-vector-classifiers" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Support Vector Classifiers<a href="support-vector-machine-svm-svr.html#support-vector-classifiers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Los vectores de soporte son las observaciones que están más cerca del hiperplano e influyen en la posición y orientación del hiperplano</strong>. Este tipo de clasificador puede considerarse como una versión extendida del clasificador de margen máximo. Cuando tratamos con datos de la vida real, encontramos que la mayoría de las observaciones están en clases superpuestas. Es por eso que se implementan clasificadores de vectores de soporte.</p>
<p>Usando estos vectores de soporte, <strong>maximizamos el margen del clasificador</strong>. Eliminar los vectores de soporte cambiará la posición del hiperplano. Estos son los puntos que nos ayudan a construir nuestro <em>SVM</em>. Consideremos un <strong>parámetro de ajuste C</strong>. Entendamos con el siguiente diagrama.</p>
<p><img src="img/02-svm/03_support_vector_classifier.png" width="900pt" height="380pt" style="display: block; margin: auto;" /></p>
<p>Podemos ver en el gráfico de la izquierda que los valores más altos de <em>C</em> generaron más errores que se consideran una <strong>violación o infracción</strong>. El diagrama de la derecha muestra un valor más bajo de <em>C</em> y no brinda suficientes posibilidades de infracción al reducir el ancho del margen.</p>
<div class="infobox note">
<p>Puede considerarse al parámetro <em>C</em> como el monto de regularización, tal que:</p>
<ul>
<li><p>Si <strong>C es bajo</strong>, el margen será más amplio y tendremos un mayor número de violaciones al margen, pero el modelo generalizará mejor</p></li>
<li><p>Si <strong>C es alto</strong>, nuestro margen será menos amplio y tendrá menos violaciones. Sin embargo, no generalizará bien.</p></li>
</ul>
</div>
<p>Este modelo es sensible a cambios en la escala de datos de entrada, por lo que será <strong>importante estandarizar las variables antes de usar este modelo</strong>.</p>
</div>
<div id="support-vector-machine" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Support Vector Machine<a href="support-vector-machine-svm-svr.html#support-vector-machine" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El enfoque de la máquina de vectores de soporte se considera durante una decisión no lineal y los datos no son separables por un clasificador de vectores de soporte, independientemente de la función de costo.</p>
<p>Cuando es casi imposible separar clases de manera no lineal, aplicamos el truco llamado <strong>truco del kernel</strong> el cual ayuda a manejar la separación de los datos.</p>
<p><img src="img/02-svm/04_polinomial_kernel_plot.png" width="900pt" height="380pt" style="display: block; margin: auto;" /></p>
<p>En el gráfico anterior, los datos que eran inseparables en una dimensión se separaron una vez que se transformaron a un espacio de dos dimensiones después de aplicar una <strong>transformación mediante kernel polinomial de segundo grado</strong>. Ahora veamos cómo manejar los datos bidimensionales linealmente inseparables.</p>
<p><img src="img/02-svm/05_kernel_polinomial_plot2.png" width="900pt" height="380pt" style="display: block; margin: auto;" /></p>
<p>En datos bidimensionales, el núcleo polinomial de segundo grado se aplica utilizando un plano lineal después de transformarlo a dimensiones superiores.</p>
</div>
<div id="el-truco-del-kernel" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> El truco del Kernel<a href="support-vector-machine-svm-svr.html#el-truco-del-kernel" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las funciones Kernel son métodos con los que se utilizan clasificadores lineales como <em>SVM</em> para clasificar puntos de datos separables no linealmente. Esto se hace representando los puntos de datos en un espacio de mayor dimensión que su original. Por ejemplo, los datos 1D se pueden representar como datos 2D en el espacio, los datos 2D se pueden representar como datos 3D, etcétera.</p>
<p>El truco del kernel ofrece una <strong>forma de calcular las relaciones entre los puntos de datos</strong> utilizando funciones del kernel y representar los datos de una manera más eficiente con menos cómputo. Los modelos que utilizan esta técnica se denominan <strong>“modelos kernelizados”</strong>.</p>
<p><img src="img/02-svm/06_kernels.png" width="700pt" height="500pt" style="display: block; margin: auto;" /></p>
<p>Hay varias funciones que utiliza SVM para realizar esta tarea. Algunos de los más comunes son:</p>
<ol style="list-style-type: decimal">
<li><strong>El núcleo lineal:</strong> Se utiliza para datos lineales. Esto simplemente representa los puntos de datos usando una relación lineal.</li>
</ol>
<p><span class="math display">\[K(x, y)=(x^T \cdot y)\]</span>
<span class="math display">\[f(x)=w^T \cdot x + b\]</span>
Esta formulación se presenta como solución al problema de optimización sobre w:</p>
<p><span class="math display">\[min_{w\in R^d} \frac{1}{2}\parallel w \parallel ^2+ C\sum_{i}^{N}{max(0, 1-y_i f(x_i))}\]</span>
<span class="math display">\[s.a. \quad y_i f(x_i) \geq 1 - max(0, 1-y_i f(x_i))\]</span>
En donde <span class="math inline">\(1-y_i f(x_i)\)</span> es la distancia de <span class="math inline">\(x_i\)</span> al correspondiente margen de la clase si <span class="math inline">\(x_i\)</span> se encuentra en el lado equivocado del margen y cero en caso contrario. De esta forma, los puntos que se encuentran lejos del margen del lado equivocado obtendrán una mayor penalización. Dar click en la siguiente <a href="https://towardsdatascience.com/support-vector-machines-soft-margin-formulation-and-kernel-trick-4c9729dc8efe">liga</a> para mayor entendimiento del problema de optimización.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Función de núcleo polinomial:</strong> Transforma los puntos de datos mediante el <strong>uso del producto escalar</strong> y la transformación de los datos en una “dimensión <em>n</em>,” <em>n</em> podría ser cualquier valor de 2, 3, etcétera, es decir, la transformación será un producto al cuadrado o superior. Por lo tanto, representar datos en un espacio de mayor dimensión utilizando los nuevos puntos transformados.</li>
</ol>
<p><span class="math display">\[K(x, y)=(c+ x^T \cdot y)^p\]</span></p>
<p>Cuando se emplea <span class="math inline">\(p=1\)</span> y <span class="math inline">\(c=0\)</span>, el resultado es el mismo que el de un kernel lineal. Si <span class="math inline">\(p&gt;1\)</span>, se generan límites de decisión no lineales, aumentando la no linealidad a medida que aumenta <em>p</em>. No suele ser recomendable emplear valores de <em>p</em> mayores 5 por problemas de <strong>overfitting</strong>.</p>
<p><img src="img/02-svm/3-15-1-poli.png" width="400pt" height="400pt" style="display: block; margin: auto;" /></p>
<ol start="3" style="list-style-type: decimal">
<li><strong>La función de base radial (RBF):</strong> Esta función se comporta como un “modelo de vecino más cercano ponderado.” Transforma los datos representándolos en dimensiones infinitas,</li>
</ol>
<p>La función Radial puede ser de Gauss o de Laplace. Esto depende de un hiperparámetro conocido como gamma <span class="math inline">\(\gamma\)</span>. Cuanto menor sea el valor del hiperparámetro, menor será el sesgo y mayor la varianza. Mientras que un valor más alto de hiperparámetro da un sesgo más alto y menor varianza. Este es el núcleo más utilizado.</p>
<p><span class="math display">\[K(x, y)=exp(-\gamma \parallel x - y\parallel^2)=exp(-\frac{\parallel x-y \parallel ^2}{2\sigma²})\]</span>
<span class="math display">\[f(x)=w^T \cdot \phi(x) + b\]</span>
Se realiza un mapeo de x a <span class="math inline">\(\phi(x)\)</span> en donde los datos son separables</p>
<p><img src="img/02-svm/svm_radial.png" width="400pt" height="400pt" style="display: block; margin: auto;" /></p>
<p>Es recomendable probar el kernel <strong>RBF</strong>. Este kernel tiene dos ventajas: que solo tiene dos hiperparámetros que optimizar (<span class="math inline">\(\gamma\)</span> y la penalización <span class="math inline">\(C\)</span> común a todos los SVM) y que su flexibilidad puede ir desde un clasificador lineal a uno muy complejo.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>La función sigmoide:</strong> También conocida como función tangente hiperbólica (Tanh), encuentra más aplicación en redes neuronales como función de activación. Esta función mapea los valores de entrada al intervalo [-1, 1].</li>
</ol>
<p><span class="math display">\[K(x, y)= tanh(\kappa x\cdot y-\delta)\]</span></p>
<p><strong>¿Por qué se llama un “truco del kernel?”</strong></p>
<p><em>SVM</em> vuelve a representar los puntos de datos no lineales utilizando cualquiera de las funciones del kernel de una manera que parece que los datos se han transformado, luego encuentra el hiperplano de separación óptimo, sin embargo, en realidad, <strong>los puntos de datos siguen siendo los mismos</strong>, en realidad no se han transformado. Es por eso que se llama un ‘truco del kernel.’</p>
</div>
<div id="support-vector-regression" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Support Vector Regression<a href="support-vector-machine-svm-svr.html#support-vector-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El problema de la regresión es encontrar una función que aproxime la relación de un dominio de datos de entrada a números reales con base en una muestra de entrenamiento. Veamos cómo funciona SVR en realidad.</p>
<p><img src="img/02-svm/svr.png" width="400pt" height="400pt" style="display: block; margin: auto;" /></p>
<p>Consideremos las dos líneas rojas como el límite de decisión y la línea verde como el hiperplano. Nuestro objetivo, cuando avanzamos con SVR, es básicamente <strong>considerar los puntos que están dentro de la línea límite de decisión</strong>. Nuestra línea de mejor ajuste es el hiperplano que tiene un número máximo de puntos.</p>
<p>Lo primero que entenderemos será el límite de decisión. Consideremos estas líneas como si estuvieran a cualquier distancia, digamos ‘a,’ del hiperplano. Entonces, estas son las líneas que dibujamos a la distancia ‘+a’ y ‘-a’ del hiperplano. Esta ‘a’ en el texto se conoce básicamente como épsilon y <strong>representa el margen</strong>.</p>
<p>Suponiendo que la ecuación del hiperplano es la siguiente:</p>
<p><span class="math display">\[Y_i = W^TX + b\]</span>
Entonces estas ecuaciones se transforman en la siguiente forma:</p>
<ul>
<li><p><span class="math inline">\(W^TX + b = +a\)</span></p></li>
<li><p><span class="math inline">\(W^TX + b = -a\)</span></p></li>
</ul>
<p>Por lo tanto, cualquier hiperplano que satisfaga nuestra SVR debería satisfacer: <span class="math inline">\(-a &lt; Y- WX+b &lt; +a\)</span></p>
<p>Nuestro objetivo principal aquí es <strong>decidir un límite de decisión a una distancia ‘a’ del hiperplano original</strong>, de modo que los puntos de datos más cercanos al hiperplano o los vectores de soporte estén dentro de esa línea límite.</p>
<div class="infobox note">
<p>Vamos a tomar solo aquellos puntos que están dentro del límite de decisión y tienen la menor tasa de error, o están dentro del margen de tolerancia. Esto nos da un mejor modelo de ajuste.</p>
</div>
</div>
<div id="ventajas-y-desventajas" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Ventajas y desventajas<a href="support-vector-machine-svm-svr.html#ventajas-y-desventajas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Ventajas</strong></p>
<ul>
<li><p>Es un modelo que ajusta bien con pocos datos</p></li>
<li><p>Son flexibles en datos no estructurados, estructurados y semiestructurados.</p></li>
<li><p>La función Kernel alivia las complejidades en casi cualquier tipo de datos.</p></li>
<li><p>Se observa menos sobreajuste en comparación con otros modelos.</p></li>
</ul>
<p><strong>Desventajas</strong></p>
<ul>
<li><p>El tiempo de entrenamiento es mayor cuando se calculan grandes conjuntos de datos.</p></li>
<li><p>Los hiperparámetros suelen ser un desafío al interpretar su impacto.</p></li>
<li><p>La interpretación general es difícil (black box).</p></li>
</ul>
</div>
<div id="ajuste-del-modelo-con-r" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Ajuste del modelo con R<a href="support-vector-machine-svm-svr.html#ajuste-del-modelo-con-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Usaremos las recetas antes implementadas para ajustar tanto el modelo de regresión como el de clasificación. Exploraremos un conjunto de hiperparámetros para elegir el mejor modelo.</p>
<p>Recordemos los pasos a seguir al ajustar un modelo</p>
<ol style="list-style-type: decimal">
<li>Separación inicial de datos ( test, train <KFCV> )</li>
<li>Pre-procesamiento e ingeniería de variables</li>
<li>Selección de tipo de modelo con hiperparámetros iniciales</li>
<li>Inicialización de workflow o pipeline</li>
<li>Creación de grid search</li>
<li><strong>Entrenamiento de modelos con hiperparámetros definidos</strong> (salvar los modelos entrenados)</li>
<li>Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</li>
<li>Selección de modelo a usar</li>
<li>Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</li>
<li>Validar poder predictivo con datos de prueba.</li>
</ol>
<div id="implementación-de-svr-en-r" class="section level3 hasAnchor" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Implementación de SVR en R<a href="support-vector-machine-svm-svr.html#implementación-de-svr-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A continuación, revisaremos paso por paso este procedimiento usando SVM como modelo. Los datos corresponden a nuestro ya conocido problema predictivo de precio de casas. Se puede encontrar los datos y documentación en el siguiente <a href="">enlace</a></p>
<p><strong>Paso 1: Separación inicial de datos ( test, train <KFCV> )</strong></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="support-vector-machine-svm-svr.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb38-2"><a href="support-vector-machine-svm-svr.html#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="support-vector-machine-svm-svr.html#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(ames)</span>
<span id="cb38-4"><a href="support-vector-machine-svm-svr.html#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="support-vector-machine-svm-svr.html#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4595</span>)</span>
<span id="cb38-6"><a href="support-vector-machine-svm-svr.html#cb38-6" aria-hidden="true" tabindex="-1"></a>ames_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(ames, <span class="at">prop =</span> <span class="fl">0.75</span>)</span>
<span id="cb38-7"><a href="support-vector-machine-svm-svr.html#cb38-7" aria-hidden="true" tabindex="-1"></a>ames_train <span class="ot">&lt;-</span> <span class="fu">training</span>(ames_split)</span>
<span id="cb38-8"><a href="support-vector-machine-svm-svr.html#cb38-8" aria-hidden="true" tabindex="-1"></a>ames_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(ames_split)</span>
<span id="cb38-9"><a href="support-vector-machine-svm-svr.html#cb38-9" aria-hidden="true" tabindex="-1"></a>ames_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(ames_train)</span></code></pre></div>
<p>Contando con datos de entrenamiento, procedemos a realizar el feature engineering para extraer las mejores características que permitirán realizar las estimaciones en el modelo.</p>
<p><strong>Paso 2: Pre-procesamiento e ingeniería de variables</strong></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="support-vector-machine-svm-svr.html#cb39-1" aria-hidden="true" tabindex="-1"></a>receta_casas <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Sale_Price <span class="sc">~</span> . , <span class="at">data =</span> ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb39-2"><a href="support-vector-machine-svm-svr.html#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_unknown</span>(Alley) <span class="sc">%&gt;%</span></span>
<span id="cb39-3"><a href="support-vector-machine-svm-svr.html#cb39-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rename</span>(<span class="at">Year_Remod =</span> Year_Remod_Add) <span class="sc">%&gt;%</span> </span>
<span id="cb39-4"><a href="support-vector-machine-svm-svr.html#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rename</span>(<span class="at">ThirdSsn_Porch =</span> Three_season_porch) <span class="sc">%&gt;%</span> </span>
<span id="cb39-5"><a href="support-vector-machine-svm-svr.html#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_ratio</span>(Bedroom_AbvGr, <span class="at">denom =</span> <span class="fu">denom_vars</span>(Gr_Liv_Area)) <span class="sc">%&gt;%</span> </span>
<span id="cb39-6"><a href="support-vector-machine-svm-svr.html#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_mutate</span>(</span>
<span id="cb39-7"><a href="support-vector-machine-svm-svr.html#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">Age_House =</span> Year_Sold <span class="sc">-</span> Year_Remod,</span>
<span id="cb39-8"><a href="support-vector-machine-svm-svr.html#cb39-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">TotalSF   =</span> Gr_Liv_Area <span class="sc">+</span> Total_Bsmt_SF,</span>
<span id="cb39-9"><a href="support-vector-machine-svm-svr.html#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">AvgRoomSF   =</span> Gr_Liv_Area <span class="sc">/</span> TotRms_AbvGrd,</span>
<span id="cb39-10"><a href="support-vector-machine-svm-svr.html#cb39-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">Pool =</span> <span class="fu">if_else</span>(Pool_Area <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb39-11"><a href="support-vector-machine-svm-svr.html#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">Exter_Cond =</span> forcats<span class="sc">::</span><span class="fu">fct_collapse</span>(Exter_Cond, <span class="at">Good =</span> <span class="fu">c</span>(<span class="st">&quot;Typical&quot;</span>, <span class="st">&quot;Good&quot;</span>, <span class="st">&quot;Excellent&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb39-12"><a href="support-vector-machine-svm-svr.html#cb39-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_relevel</span>(Exter_Cond, <span class="at">ref_level =</span> <span class="st">&quot;Good&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb39-13"><a href="support-vector-machine-svm-svr.html#cb39-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_predictors</span>(), <span class="sc">-</span><span class="fu">all_nominal</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb39-14"><a href="support-vector-machine-svm-svr.html#cb39-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb39-15"><a href="support-vector-machine-svm-svr.html#cb39-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_interact</span>(<span class="sc">~</span> Second_Flr_SF<span class="sc">:</span>First_Flr_SF) <span class="sc">%&gt;%</span> </span>
<span id="cb39-16"><a href="support-vector-machine-svm-svr.html#cb39-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_interact</span>(<span class="sc">~</span> <span class="fu">matches</span>(<span class="st">&quot;Bsmt_Cond&quot;</span>)<span class="sc">:</span>TotRms_AbvGrd) <span class="sc">%&gt;%</span> </span>
<span id="cb39-17"><a href="support-vector-machine-svm-svr.html#cb39-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rm</span>(</span>
<span id="cb39-18"><a href="support-vector-machine-svm-svr.html#cb39-18" aria-hidden="true" tabindex="-1"></a>    First_Flr_SF, Second_Flr_SF, Year_Remod,</span>
<span id="cb39-19"><a href="support-vector-machine-svm-svr.html#cb39-19" aria-hidden="true" tabindex="-1"></a>    Bsmt_Full_Bath, Bsmt_Half_Bath, </span>
<span id="cb39-20"><a href="support-vector-machine-svm-svr.html#cb39-20" aria-hidden="true" tabindex="-1"></a>    Kitchen_AbvGr, BsmtFin_Type_1_Unf, </span>
<span id="cb39-21"><a href="support-vector-machine-svm-svr.html#cb39-21" aria-hidden="true" tabindex="-1"></a>    Total_Bsmt_SF, Kitchen_AbvGr, Pool_Area, </span>
<span id="cb39-22"><a href="support-vector-machine-svm-svr.html#cb39-22" aria-hidden="true" tabindex="-1"></a>    Gr_Liv_Area, Sale_Type_Oth, Sale_Type_VWD</span>
<span id="cb39-23"><a href="support-vector-machine-svm-svr.html#cb39-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb39-24"><a href="support-vector-machine-svm-svr.html#cb39-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb39-25"><a href="support-vector-machine-svm-svr.html#cb39-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-26"><a href="support-vector-machine-svm-svr.html#cb39-26" aria-hidden="true" tabindex="-1"></a>receta_casas</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         73
## 
## Training data contained 2197 data points and no missing data.
## 
## Operations:
## 
## Unknown factor level assignment for Alley [trained]
## Variable renaming for Year_Remod [trained]
## Variable renaming for ThirdSsn_Porch [trained]
## Ratios from Bedroom_AbvGr, Gr_Liv_Area [trained]
## Variable mutation for ~Year_Sold - Year_Remod, ~Gr_Liv_Area + To... [trained]
## Re-order factor level to ref_level for Exter_Cond [trained]
## Centering and scaling for Lot_Frontage, Lot_Area, Year_Built, Year_Remod,... [trained]
## Dummy variables from MS_SubClass, MS_Zoning, Street, Alley, Lot_Shape, Land_Co... [trained]
## Interactions with Second_Flr_SF:First_Flr_SF [trained]
## Interactions with (Bsmt_Cond_Fair + Bsmt_Cond_Good + Bsmt_Cond_No_Ba... [trained]
## Variables removed First_Flr_SF, Second_Flr_SF, Year_Remod, Bsmt_Full_Bath... [trained]</code></pre>
<p>Recordemos que la función <strong>recipe()</strong> solo son los pasos a seguir, necesitamos usar la función <strong>prep()</strong> que nos devuelve una receta actualizada con las estimaciones y la función <strong>juice()</strong> que nos devuelve la matriz de diseño.</p>
<p>Una vez que la receta de transformación de datos está lista, procedemos a implementar el pipeline del modelo de interés. Existen diversas funciones dentro de <em>tidymodels</em> para implementar estos modelos, entra las cuales se encuentran:</p>
<ul>
<li>Base lineal: svm_lineal()</li>
<li>Base polinomial: svm_poly()</li>
<li>Base radial: svm_rbf()</li>
</ul>
<p><strong>Paso 3: Selección de tipo de modelo con hiperparámetros iniciales</strong></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="support-vector-machine-svm-svr.html#cb41-1" aria-hidden="true" tabindex="-1"></a>svm_model <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>(</span>
<span id="cb41-2"><a href="support-vector-machine-svm-svr.html#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>,</span>
<span id="cb41-3"><a href="support-vector-machine-svm-svr.html#cb41-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">tune</span>(),</span>
<span id="cb41-4"><a href="support-vector-machine-svm-svr.html#cb41-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">rbf_sigma =</span> <span class="fu">tune</span>(),</span>
<span id="cb41-5"><a href="support-vector-machine-svm-svr.html#cb41-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">margin =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb41-6"><a href="support-vector-machine-svm-svr.html#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set_engine</span>(<span class="st">&quot;kernlab&quot;</span>)</span>
<span id="cb41-7"><a href="support-vector-machine-svm-svr.html#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="support-vector-machine-svm-svr.html#cb41-8" aria-hidden="true" tabindex="-1"></a>svm_model</span></code></pre></div>
<pre><code>## Radial Basis Function Support Vector Machine Specification (regression)
## 
## Main Arguments:
##   cost = tune()
##   rbf_sigma = tune()
##   margin = tune()
## 
## Computational engine: kernlab</code></pre>
<p><strong>Paso 4: Inicialización de workflow o pipeline</strong></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="support-vector-machine-svm-svr.html#cb43-1" aria-hidden="true" tabindex="-1"></a>svm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb43-2"><a href="support-vector-machine-svm-svr.html#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(receta_casas) <span class="sc">%&gt;%</span> </span>
<span id="cb43-3"><a href="support-vector-machine-svm-svr.html#cb43-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_model)</span>
<span id="cb43-4"><a href="support-vector-machine-svm-svr.html#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="support-vector-machine-svm-svr.html#cb43-5" aria-hidden="true" tabindex="-1"></a>svm_workflow</span></code></pre></div>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: svm_rbf()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 11 Recipe Steps
## 
## • step_unknown()
## • step_rename()
## • step_rename()
## • step_ratio()
## • step_mutate()
## • step_relevel()
## • step_normalize()
## • step_dummy()
## • step_interact()
## • step_interact()
## • ...
## • and 1 more step.
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Radial Basis Function Support Vector Machine Specification (regression)
## 
## Main Arguments:
##   cost = tune()
##   rbf_sigma = tune()
##   margin = tune()
## 
## Computational engine: kernlab</code></pre>
<p><strong>Paso 5: Creación de grid search</strong></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="support-vector-machine-svm-svr.html#cb45-1" aria-hidden="true" tabindex="-1"></a>svm_parameters_set <span class="ot">&lt;-</span> svm_workflow <span class="sc">%&gt;%</span> </span>
<span id="cb45-2"><a href="support-vector-machine-svm-svr.html#cb45-2" aria-hidden="true" tabindex="-1"></a>  hardhat<span class="sc">::</span><span class="fu">extract_parameter_set_dials</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb45-3"><a href="support-vector-machine-svm-svr.html#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(</span>
<span id="cb45-4"><a href="support-vector-machine-svm-svr.html#cb45-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">cost =</span> <span class="fu">cost</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>)),</span>
<span id="cb45-5"><a href="support-vector-machine-svm-svr.html#cb45-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">rbf_sigma =</span> <span class="fu">rbf_sigma</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)), </span>
<span id="cb45-6"><a href="support-vector-machine-svm-svr.html#cb45-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">margin =</span> <span class="fu">svm_margin</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb45-7"><a href="support-vector-machine-svm-svr.html#cb45-7" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb45-8"><a href="support-vector-machine-svm-svr.html#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="support-vector-machine-svm-svr.html#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb45-10"><a href="support-vector-machine-svm-svr.html#cb45-10" aria-hidden="true" tabindex="-1"></a>svm_grid <span class="ot">&lt;-</span> svm_parameters_set <span class="sc">%&gt;%</span> </span>
<span id="cb45-11"><a href="support-vector-machine-svm-svr.html#cb45-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grid_max_entropy</span>(<span class="at">size =</span> <span class="dv">100</span>)</span>
<span id="cb45-12"><a href="support-vector-machine-svm-svr.html#cb45-12" aria-hidden="true" tabindex="-1"></a>svm_grid</span></code></pre></div>
<pre><code>## # A tibble: 100 × 3
##     cost rbf_sigma margin
##    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;
##  1  1.22    0.504   0.571
##  2  1.41    1.22    0.329
##  3  1.33    0.111   1.38 
##  4  1.35    0.0935 -1.65 
##  5  1.04    0.937   1.48 
##  6  1.14    0.0154 -1.91 
##  7  1.39   70.2    -1.98 
##  8  1.07    1.16   -0.487
##  9  1.17    1.34    0.948
## 10  1.02    0.0303  0.230
## # … with 90 more rows</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="support-vector-machine-svm-svr.html#cb47-1" aria-hidden="true" tabindex="-1"></a>ctrl_grid <span class="ot">&lt;-</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> T, <span class="at">verbose =</span> T)</span></code></pre></div>
<p><strong>Paso 6: Entrenamiento de modelos con hiperparámetros definidos</strong></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="support-vector-machine-svm-svr.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb48-2"><a href="support-vector-machine-svm-svr.html#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="support-vector-machine-svm-svr.html#cb48-3" aria-hidden="true" tabindex="-1"></a>UseCores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb48-4"><a href="support-vector-machine-svm-svr.html#cb48-4" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(UseCores)</span>
<span id="cb48-5"><a href="support-vector-machine-svm-svr.html#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cluster)</span>
<span id="cb48-6"><a href="support-vector-machine-svm-svr.html#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="support-vector-machine-svm-svr.html#cb48-7" aria-hidden="true" tabindex="-1"></a>svm1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb48-8"><a href="support-vector-machine-svm-svr.html#cb48-8" aria-hidden="true" tabindex="-1"></a>svm_tune_result <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb48-9"><a href="support-vector-machine-svm-svr.html#cb48-9" aria-hidden="true" tabindex="-1"></a>  svm_workflow,</span>
<span id="cb48-10"><a href="support-vector-machine-svm-svr.html#cb48-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> ames_folds,</span>
<span id="cb48-11"><a href="support-vector-machine-svm-svr.html#cb48-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> svm_grid,</span>
<span id="cb48-12"><a href="support-vector-machine-svm-svr.html#cb48-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(rmse, mae, mape),</span>
<span id="cb48-13"><a href="support-vector-machine-svm-svr.html#cb48-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> ctrl_grid</span>
<span id="cb48-14"><a href="support-vector-machine-svm-svr.html#cb48-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-15"><a href="support-vector-machine-svm-svr.html#cb48-15" aria-hidden="true" tabindex="-1"></a>svm2 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); svm2 <span class="sc">-</span> svm1</span>
<span id="cb48-16"><a href="support-vector-machine-svm-svr.html#cb48-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-17"><a href="support-vector-machine-svm-svr.html#cb48-17" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cluster)</span>
<span id="cb48-18"><a href="support-vector-machine-svm-svr.html#cb48-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-19"><a href="support-vector-machine-svm-svr.html#cb48-19" aria-hidden="true" tabindex="-1"></a>svm_tune_result <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/svm_model_reg.rds&quot;</span>)</span></code></pre></div>
<p>Podemos obtener las métricas de cada <em>fold</em> con el siguiente código:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="support-vector-machine-svm-svr.html#cb49-1" aria-hidden="true" tabindex="-1"></a>svm_tune_result <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/svm_model_reg.rds&quot;</span>)</span>
<span id="cb49-2"><a href="support-vector-machine-svm-svr.html#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="support-vector-machine-svm-svr.html#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">unnest</span>(svm_tune_result, .metrics)</span></code></pre></div>
<pre><code>## # A tibble: 3,000 × 11
##    splits             id      cost rbf_sigma margin .metric .estimator .estimate
##    &lt;list&gt;             &lt;chr&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
##  1 &lt;split [1977/220]&gt; Fold01  1.04   0.00515  0.543 rmse    standard     41851. 
##  2 &lt;split [1977/220]&gt; Fold01  1.04   0.00515  0.543 mae     standard     29737. 
##  3 &lt;split [1977/220]&gt; Fold01  1.04   0.00515  0.543 mape    standard        19.8
##  4 &lt;split [1977/220]&gt; Fold01  1.12 688.       1.55  rmse    standard     98784. 
##  5 &lt;split [1977/220]&gt; Fold01  1.12 688.       1.55  mae     standard     86126. 
##  6 &lt;split [1977/220]&gt; Fold01  1.12 688.       1.55  mape    standard        63.4
##  7 &lt;split [1977/220]&gt; Fold01  1.15   0.0145  -0.643 rmse    standard     41706. 
##  8 &lt;split [1977/220]&gt; Fold01  1.15   0.0145  -0.643 mae     standard     28971. 
##  9 &lt;split [1977/220]&gt; Fold01  1.15   0.0145  -0.643 mape    standard        19.7
## 10 &lt;split [1977/220]&gt; Fold01  1.20 103.      -1.51  rmse    standard     98356. 
## # … with 2,990 more rows, and 3 more variables: .config &lt;chr&gt;, .notes &lt;list&gt;,
## #   .predictions &lt;list&gt;</code></pre>
<p><strong>Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</strong></p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="support-vector-machine-svm-svr.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(svm_tune_result)</span></code></pre></div>
<pre><code>## # A tibble: 300 × 9
##     cost rbf_sigma margin .metric .estimator    mean     n  std_err .config     
##    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       
##  1  1.04   0.00515  0.543 mae     standard   27905.     10  604.    Preprocesso…
##  2  1.04   0.00515  0.543 mape    standard      17.2    10    0.579 Preprocesso…
##  3  1.04   0.00515  0.543 rmse    standard   39638.     10 1268.    Preprocesso…
##  4  1.12 688.       1.55  mae     standard   79477.     10  903.    Preprocesso…
##  5  1.12 688.       1.55  mape    standard      59.3    10    1.23  Preprocesso…
##  6  1.12 688.       1.55  rmse    standard   93686.     10 1127.    Preprocesso…
##  7  1.15   0.0145  -0.643 mae     standard   27913.     10  657.    Preprocesso…
##  8  1.15   0.0145  -0.643 mape    standard      17.7    10    0.600 Preprocesso…
##  9  1.15   0.0145  -0.643 rmse    standard   39121.     10 1424.    Preprocesso…
## 10  1.20 103.      -1.51  mae     standard   78820.     10  912.    Preprocesso…
## # … with 290 more rows</code></pre>
<p>En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="support-vector-machine-svm-svr.html#cb53-1" aria-hidden="true" tabindex="-1"></a>svm_tune_result <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="support-vector-machine-svm-svr.html#cb54-1" aria-hidden="true" tabindex="-1"></a>svm_tune_result <span class="sc">%&gt;%</span> <span class="fu">show_best</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;mape&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 9
##     cost rbf_sigma  margin .metric .estimator  mean     n std_err .config       
##    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;         
##  1  1.24   0.0175   0.226  mape    standard    14.3    10   0.558 Preprocessor1…
##  2  1.13   0.0211   0.319  mape    standard    14.8    10   0.569 Preprocessor1…
##  3  1.38   0.0308   0.320  mape    standard    14.9    10   0.574 Preprocessor1…
##  4  1.13   0.00549 -0.0512 mape    standard    14.9    10   0.584 Preprocessor1…
##  5  1.04   0.00398 -0.0321 mape    standard    15.3    10   0.611 Preprocessor1…
##  6  1.10   0.00303  0.0327 mape    standard    15.5    10   0.623 Preprocessor1…
##  7  1.17   0.00383  0.353  mape    standard    16.1    10   0.615 Preprocessor1…
##  8  1.06   0.00165  0.0561 mape    standard    16.2    10   0.628 Preprocessor1…
##  9  1.28   0.00380 -0.388  mape    standard    16.2    10   0.609 Preprocessor1…
## 10  1.36   0.00299  0.409  mape    standard    16.6    10   0.619 Preprocessor1…</code></pre>
<p><strong>Paso 8: Selección de modelo a usar</strong></p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="support-vector-machine-svm-svr.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Selección del mejor modelo según la métrica MAPE</span></span>
<span id="cb56-2"><a href="support-vector-machine-svm-svr.html#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="support-vector-machine-svm-svr.html#cb56-3" aria-hidden="true" tabindex="-1"></a>svm_regression_best_model <span class="ot">&lt;-</span> <span class="fu">select_best</span>(svm_tune_result, <span class="at">metric =</span> <span class="st">&quot;mape&quot;</span>)</span>
<span id="cb56-4"><a href="support-vector-machine-svm-svr.html#cb56-4" aria-hidden="true" tabindex="-1"></a>svm_regression_best_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##    cost rbf_sigma margin .config               
##   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 
## 1  1.24    0.0175  0.226 Preprocessor1_Model075</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="support-vector-machine-svm-svr.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Selección del modelo más regularizado a menos de una desviación estandar, según la métrica MAPE</span></span>
<span id="cb58-2"><a href="support-vector-machine-svm-svr.html#cb58-2" aria-hidden="true" tabindex="-1"></a>svm_regression_best_1se_model <span class="ot">&lt;-</span> svm_tune_result <span class="sc">%&gt;%</span> </span>
<span id="cb58-3"><a href="support-vector-machine-svm-svr.html#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_by_one_std_err</span>(<span class="at">metric =</span> <span class="st">&quot;mape&quot;</span>, <span class="st">&quot;mape&quot;</span>)</span>
<span id="cb58-4"><a href="support-vector-machine-svm-svr.html#cb58-4" aria-hidden="true" tabindex="-1"></a>svm_regression_best_1se_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 11
##    cost rbf_sigma margin .metric .estimator  mean     n std_err .config    .best
##   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;
## 1  1.13    0.0211  0.319 mape    standard    14.8    10   0.569 Preproces…  14.3
## # … with 1 more variable: .bound &lt;dbl&gt;</code></pre>
<p><strong>Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</strong></p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="support-vector-machine-svm-svr.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelo final </span></span>
<span id="cb60-2"><a href="support-vector-machine-svm-svr.html#cb60-2" aria-hidden="true" tabindex="-1"></a>svm_regression_final_model <span class="ot">&lt;-</span> svm_workflow <span class="sc">%&gt;%</span></span>
<span id="cb60-3"><a href="support-vector-machine-svm-svr.html#cb60-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(svm_regression_best_1se_model) <span class="sc">%&gt;%</span></span>
<span id="cb60-4"><a href="support-vector-machine-svm-svr.html#cb60-4" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(<span class="at">data =</span> ames_train)</span>
<span id="cb60-5"><a href="support-vector-machine-svm-svr.html#cb60-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb60-6"><a href="support-vector-machine-svm-svr.html#cb60-6" aria-hidden="true" tabindex="-1"></a>svm_regression_final_model</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: svm_rbf()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 11 Recipe Steps
## 
## • step_unknown()
## • step_rename()
## • step_rename()
## • step_ratio()
## • step_mutate()
## • step_relevel()
## • step_normalize()
## • step_dummy()
## • step_interact()
## • step_interact()
## • ...
## • and 1 more step.
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Support Vector Machine object of class &quot;ksvm&quot; 
## 
## SV type: eps-svr  (regression) 
##  parameter : epsilon = 0.318837530910969  cost C = 1.1300031747186 
## 
## Gaussian Radial Basis kernel function. 
##  Hyperparameter : sigma =  0.0210599956279017 
## 
## Number of Support Vectors : 709 
## 
## Objective Function Value : -221.4799 
## Training error : 0.149207</code></pre>
<p>Como hemos hablado anteriormente, este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.</p>
<p>Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos <a href="https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba">data leakage</a>. Para enfrentar esto, ayuda estimar y ordenar el valor de importancia del modelo</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="support-vector-machine-svm-svr.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb62-2"><a href="support-vector-machine-svm-svr.html#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="support-vector-machine-svm-svr.html#cb62-3" aria-hidden="true" tabindex="-1"></a>ames_importance <span class="ot">&lt;-</span> svm_regression_final_model <span class="sc">%&gt;%</span> </span>
<span id="cb62-4"><a href="support-vector-machine-svm-svr.html#cb62-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb62-5"><a href="support-vector-machine-svm-svr.html#cb62-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vi</span>(</span>
<span id="cb62-6"><a href="support-vector-machine-svm-svr.html#cb62-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;permute&quot;</span>,</span>
<span id="cb62-7"><a href="support-vector-machine-svm-svr.html#cb62-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">nsim =</span> <span class="dv">10</span>,</span>
<span id="cb62-8"><a href="support-vector-machine-svm-svr.html#cb62-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">&quot;Sale_Price&quot;</span>,</span>
<span id="cb62-9"><a href="support-vector-machine-svm-svr.html#cb62-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>,</span>
<span id="cb62-10"><a href="support-vector-machine-svm-svr.html#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">pred_wrapper =</span> kernlab<span class="sc">::</span>predict, </span>
<span id="cb62-11"><a href="support-vector-machine-svm-svr.html#cb62-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">train =</span> <span class="fu">juice</span>(receta_casas)</span>
<span id="cb62-12"><a href="support-vector-machine-svm-svr.html#cb62-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb62-13"><a href="support-vector-machine-svm-svr.html#cb62-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-14"><a href="support-vector-machine-svm-svr.html#cb62-14" aria-hidden="true" tabindex="-1"></a>ames_importance <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/vip_ames_svm.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="support-vector-machine-svm-svr.html#cb63-1" aria-hidden="true" tabindex="-1"></a>ames_importance <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/vip_ames_svm.rds&quot;</span>)</span>
<span id="cb63-2"><a href="support-vector-machine-svm-svr.html#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="support-vector-machine-svm-svr.html#cb63-3" aria-hidden="true" tabindex="-1"></a>ames_importance</span></code></pre></div>
<pre><code>## # A tibble: 274 × 3
##    Variable      Importance StDev
##    &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;
##  1 Year_Built        13445.  595.
##  2 Garage_Area        8866.  409.
##  3 TotRms_AbvGrd      8788.  393.
##  4 Fireplaces         5900.  475.
##  5 Mas_Vnr_Area       5731.  186.
##  6 Full_Bath          4544.  339.
##  7 Garage_Cars        3639.  368.
##  8 Lot_Area           2981.  261.
##  9 Bedroom_AbvGr      2564.  296.
## 10 BsmtFin_SF_1       2425.  156.
## # … with 264 more rows</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="support-vector-machine-svm-svr.html#cb65-1" aria-hidden="true" tabindex="-1"></a>ames_importance <span class="sc">%&gt;%</span></span>
<span id="cb65-2"><a href="support-vector-machine-svm-svr.html#cb65-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Variable =</span> forcats<span class="sc">::</span><span class="fu">fct_reorder</span>(Variable, Importance)) <span class="sc">%&gt;%</span></span>
<span id="cb65-3"><a href="support-vector-machine-svm-svr.html#cb65-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_max</span>(Importance, <span class="at">n =</span> <span class="dv">20</span>) <span class="sc">%&gt;%</span></span>
<span id="cb65-4"><a href="support-vector-machine-svm-svr.html#cb65-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(Importance, Variable, <span class="at">color =</span> Variable)) <span class="sc">+</span></span>
<span id="cb65-5"><a href="support-vector-machine-svm-svr.html#cb65-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">xmin =</span> Importance <span class="sc">-</span> StDev, <span class="at">xmax =</span> Importance <span class="sc">+</span> StDev),</span>
<span id="cb65-6"><a href="support-vector-machine-svm-svr.html#cb65-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">size =</span> <span class="fl">1.3</span>) <span class="sc">+</span></span>
<span id="cb65-7"><a href="support-vector-machine-svm-svr.html#cb65-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb65-8"><a href="support-vector-machine-svm-svr.html#cb65-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb65-9"><a href="support-vector-machine-svm-svr.html#cb65-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Variable Importance Measure&quot;</span>)</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p><strong>Paso 10: Validar poder predictivo con datos de prueba</strong></p>
<p>Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="support-vector-machine-svm-svr.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicciones</span></span>
<span id="cb66-2"><a href="support-vector-machine-svm-svr.html#cb66-2" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_regression_final_model, ames_test) <span class="sc">%&gt;%</span> </span>
<span id="cb66-3"><a href="support-vector-machine-svm-svr.html#cb66-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">bind_cols</span>(<span class="at">truth =</span> ames_test<span class="sc">$</span>Sale_Price) <span class="sc">%&gt;%</span> </span>
<span id="cb66-4"><a href="support-vector-machine-svm-svr.html#cb66-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">pred_svm_reg =</span> .pred, <span class="at">Sale_Price =</span> truth)</span>
<span id="cb66-5"><a href="support-vector-machine-svm-svr.html#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="support-vector-machine-svm-svr.html#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 2
##   pred_svm_reg Sale_Price
##          &lt;dbl&gt;      &lt;int&gt;
## 1      143363.     105000
## 2      183725.     185000
## 3      179908.     180400
## 4      127895.     141000
## 5      217114.     210000
## 6      196308.     216000</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="support-vector-machine-svm-svr.html#cb68-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> yardstick<span class="sc">::</span><span class="fu">metrics</span>(Sale_Price, pred_svm_reg)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard   36200.   
## 2 rsq     standard       0.798
## 3 mae     standard   24681.</code></pre>
<p>Es posible definir nuestro propio conjunto de metricas que deseamos reportar creando este objeto:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="support-vector-machine-svm-svr.html#cb70-1" aria-hidden="true" tabindex="-1"></a>multi_metric <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(rmse, rsq, mae, mape, ccc)</span>
<span id="cb70-2"><a href="support-vector-machine-svm-svr.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">multi_metric</span>(results, <span class="at">truth =</span> Sale_Price, <span class="at">estimate =</span> pred_svm_reg) <span class="sc">%&gt;%</span> </span>
<span id="cb70-3"><a href="support-vector-machine-svm-svr.html#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.estimate =</span> <span class="fu">round</span>(.estimate, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## # A tibble: 5 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard    36200.  
## 2 rsq     standard        0.8 
## 3 mae     standard    24681.  
## 4 mape    standard       14.8 
## 5 ccc     standard        0.89</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="support-vector-machine-svm-svr.html#cb72-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb72-2"><a href="support-vector-machine-svm-svr.html#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> pred_svm_reg, <span class="at">y =</span> Sale_Price)) <span class="sc">+</span></span>
<span id="cb72-3"><a href="support-vector-machine-svm-svr.html#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb72-4"><a href="support-vector-machine-svm-svr.html#cb72-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb72-5"><a href="support-vector-machine-svm-svr.html#cb72-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Prediction&quot;</span>) <span class="sc">+</span></span>
<span id="cb72-6"><a href="support-vector-machine-svm-svr.html#cb72-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Observation&quot;</span>) <span class="sc">+</span></span>
<span id="cb72-7"><a href="support-vector-machine-svm-svr.html#cb72-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Comparisson&quot;</span>)</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
</div>
<div id="implementación-de-svm-en-r" class="section level3 hasAnchor" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> Implementación de SVM en R<a href="support-vector-machine-svm-svr.html#implementación-de-svm-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Es turno de revisar la implementación de SVM con nuestro bien conocido problema de predicción de cancelación de servicios de telecomunicaciones. Los datos se encuentran disponibles en el siguiente <a href="https://drive.google.com/drive/folders/1mlDGHvUy-81qfvQi_iB7tqMb9yhy3vyh?usp=sharing">enlace</a>:</p>
<p>Los pasos para implementar en <em>R</em> este modelo predictivo son los mismos, cambiando únicamente las especificaciones del tipo de modelo, pre-procesamiento e hiper-parámetros.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="support-vector-machine-svm-svr.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb73-2"><a href="support-vector-machine-svm-svr.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb73-3"><a href="support-vector-machine-svm-svr.html#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb73-4"><a href="support-vector-machine-svm-svr.html#cb73-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-5"><a href="support-vector-machine-svm-svr.html#cb73-5" aria-hidden="true" tabindex="-1"></a>telco <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/Churn.csv&quot;</span>)</span>
<span id="cb73-6"><a href="support-vector-machine-svm-svr.html#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(telco)</span></code></pre></div>
<pre><code>## Rows: 7,043
## Columns: 21
## $ customerID       &lt;chr&gt; &quot;7590-VHVEG&quot;, &quot;5575-GNVDE&quot;, &quot;3668-QPYBK&quot;, &quot;7795-CFOCW…
## $ gender           &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;,…
## $ SeniorCitizen    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ Partner          &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes…
## $ Dependents       &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;…
## $ tenure           &lt;dbl&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…
## $ PhoneService     &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, …
## $ MultipleLines    &lt;chr&gt; &quot;No phone service&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No phone service&quot;, &quot;…
## $ InternetService  &lt;chr&gt; &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;Fiber optic&quot;, &quot;Fiber opt…
## $ OnlineSecurity   &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;…
## $ OnlineBackup     &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;N…
## $ DeviceProtection &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Y…
## $ TechSupport      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes…
## $ StreamingTV      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Ye…
## $ StreamingMovies  &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes…
## $ Contract         &lt;chr&gt; &quot;Month-to-month&quot;, &quot;One year&quot;, &quot;Month-to-month&quot;, &quot;One …
## $ PaperlessBilling &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, …
## $ PaymentMethod    &lt;chr&gt; &quot;Electronic check&quot;, &quot;Mailed check&quot;, &quot;Mailed check&quot;, &quot;…
## $ MonthlyCharges   &lt;dbl&gt; 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…
## $ TotalCharges     &lt;dbl&gt; 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…
## $ Churn            &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Y…</code></pre>
<p><strong>Paso 1: Separación inicial de datos ( test, train <KFCV> )</strong></p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="support-vector-machine-svm-svr.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb75-2"><a href="support-vector-machine-svm-svr.html#cb75-2" aria-hidden="true" tabindex="-1"></a>telco_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(telco, <span class="at">prop =</span> .<span class="dv">70</span>)</span>
<span id="cb75-3"><a href="support-vector-machine-svm-svr.html#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="support-vector-machine-svm-svr.html#cb75-4" aria-hidden="true" tabindex="-1"></a>telco_train <span class="ot">&lt;-</span> <span class="fu">training</span>(telco_split)</span>
<span id="cb75-5"><a href="support-vector-machine-svm-svr.html#cb75-5" aria-hidden="true" tabindex="-1"></a>telco_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(telco_split)</span>
<span id="cb75-6"><a href="support-vector-machine-svm-svr.html#cb75-6" aria-hidden="true" tabindex="-1"></a>telco_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(telco_train)</span>
<span id="cb75-7"><a href="support-vector-machine-svm-svr.html#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="support-vector-machine-svm-svr.html#cb75-8" aria-hidden="true" tabindex="-1"></a>telco_folds</span></code></pre></div>
<pre><code>## #  10-fold cross-validation 
## # A tibble: 10 × 2
##    splits             id    
##    &lt;list&gt;             &lt;chr&gt; 
##  1 &lt;split [4437/493]&gt; Fold01
##  2 &lt;split [4437/493]&gt; Fold02
##  3 &lt;split [4437/493]&gt; Fold03
##  4 &lt;split [4437/493]&gt; Fold04
##  5 &lt;split [4437/493]&gt; Fold05
##  6 &lt;split [4437/493]&gt; Fold06
##  7 &lt;split [4437/493]&gt; Fold07
##  8 &lt;split [4437/493]&gt; Fold08
##  9 &lt;split [4437/493]&gt; Fold09
## 10 &lt;split [4437/493]&gt; Fold10</code></pre>
<p><strong>Paso 2: Pre-procesamiento e ingeniería de variables</strong></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="support-vector-machine-svm-svr.html#cb77-1" aria-hidden="true" tabindex="-1"></a>binner <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb77-2"><a href="support-vector-machine-svm-svr.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">cut</span>(x, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">12</span>, <span class="dv">24</span>, <span class="dv">36</span>,<span class="dv">48</span>,<span class="dv">60</span>,<span class="dv">72</span>), <span class="at">include.lowest =</span> <span class="cn">TRUE</span>)</span>
<span id="cb77-3"><a href="support-vector-machine-svm-svr.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>(x)</span>
<span id="cb77-4"><a href="support-vector-machine-svm-svr.html#cb77-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb77-5"><a href="support-vector-machine-svm-svr.html#cb77-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-6"><a href="support-vector-machine-svm-svr.html#cb77-6" aria-hidden="true" tabindex="-1"></a>telco_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Churn <span class="sc">~</span> ., <span class="at">data =</span> telco_train) <span class="sc">%&gt;%</span> </span>
<span id="cb77-7"><a href="support-vector-machine-svm-svr.html#cb77-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(customerID, <span class="at">new_role =</span> <span class="st">&quot;id variable&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb77-8"><a href="support-vector-machine-svm-svr.html#cb77-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_num2factor</span>(</span>
<span id="cb77-9"><a href="support-vector-machine-svm-svr.html#cb77-9" aria-hidden="true" tabindex="-1"></a>    tenure, <span class="at">transform =</span> binner, </span>
<span id="cb77-10"><a href="support-vector-machine-svm-svr.html#cb77-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;0-1 year&quot;</span>, <span class="st">&quot;1-2 years&quot;</span>, <span class="st">&quot;2-3 years&quot;</span>, <span class="st">&quot;3-4 years&quot;</span>, <span class="st">&quot;4-5 years&quot;</span>, <span class="st">&quot;5-6 years&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb77-11"><a href="support-vector-machine-svm-svr.html#cb77-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb77-12"><a href="support-vector-machine-svm-svr.html#cb77-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb77-13"><a href="support-vector-machine-svm-svr.html#cb77-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_median</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb77-14"><a href="support-vector-machine-svm-svr.html#cb77-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_rm</span>(customerID, <span class="at">skip=</span>T) <span class="sc">%&gt;%</span> </span>
<span id="cb77-15"><a href="support-vector-machine-svm-svr.html#cb77-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb77-16"><a href="support-vector-machine-svm-svr.html#cb77-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-17"><a href="support-vector-machine-svm-svr.html#cb77-17" aria-hidden="true" tabindex="-1"></a>telco_rec</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##         role #variables
##  id variable          1
##      outcome          1
##    predictor         19
## 
## Training data contained 4930 data points and 10 incomplete rows. 
## 
## Operations:
## 
## Factor variables from tenure [trained]
## Centering and scaling for SeniorCitizen, MonthlyCharges, TotalCharges [trained]
## Dummy variables from gender, Partner, Dependents, tenure, PhoneService, Multip... [trained]
## Median imputation for SeniorCitizen, MonthlyCharges, TotalCharges, ge... [trained]
## Variables removed customerID [trained]</code></pre>
<p><strong>Paso 3: Selección de tipo de modelo con hiperparámetros iniciales</strong></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="support-vector-machine-svm-svr.html#cb79-1" aria-hidden="true" tabindex="-1"></a>svm_class_model <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>(</span>
<span id="cb79-2"><a href="support-vector-machine-svm-svr.html#cb79-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb79-3"><a href="support-vector-machine-svm-svr.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">cost =</span> <span class="fu">tune</span>(),</span>
<span id="cb79-4"><a href="support-vector-machine-svm-svr.html#cb79-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">rbf_sigma =</span> <span class="fu">tune</span>(),</span>
<span id="cb79-5"><a href="support-vector-machine-svm-svr.html#cb79-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">margin =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb79-6"><a href="support-vector-machine-svm-svr.html#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set_engine</span>(<span class="st">&quot;kernlab&quot;</span>)</span>
<span id="cb79-7"><a href="support-vector-machine-svm-svr.html#cb79-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-8"><a href="support-vector-machine-svm-svr.html#cb79-8" aria-hidden="true" tabindex="-1"></a>svm_class_model</span></code></pre></div>
<pre><code>## Radial Basis Function Support Vector Machine Specification (classification)
## 
## Main Arguments:
##   cost = tune()
##   rbf_sigma = tune()
##   margin = tune()
## 
## Computational engine: kernlab</code></pre>
<p><strong>Paso 4: Inicialización de workflow o pipeline</strong></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="support-vector-machine-svm-svr.html#cb81-1" aria-hidden="true" tabindex="-1"></a>svm_class_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb81-2"><a href="support-vector-machine-svm-svr.html#cb81-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(telco_rec) <span class="sc">%&gt;%</span> </span>
<span id="cb81-3"><a href="support-vector-machine-svm-svr.html#cb81-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_class_model)</span>
<span id="cb81-4"><a href="support-vector-machine-svm-svr.html#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="support-vector-machine-svm-svr.html#cb81-5" aria-hidden="true" tabindex="-1"></a>svm_class_workflow</span></code></pre></div>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: svm_rbf()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 5 Recipe Steps
## 
## • step_num2factor()
## • step_normalize()
## • step_dummy()
## • step_impute_median()
## • step_rm()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Radial Basis Function Support Vector Machine Specification (classification)
## 
## Main Arguments:
##   cost = tune()
##   rbf_sigma = tune()
##   margin = tune()
## 
## Computational engine: kernlab</code></pre>
<p><strong>Paso 5: Creación de grid search</strong></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="support-vector-machine-svm-svr.html#cb83-1" aria-hidden="true" tabindex="-1"></a>svm_class_parameters_set <span class="ot">&lt;-</span> svm_class_workflow <span class="sc">%&gt;%</span> </span>
<span id="cb83-2"><a href="support-vector-machine-svm-svr.html#cb83-2" aria-hidden="true" tabindex="-1"></a>  hardhat<span class="sc">::</span><span class="fu">extract_parameter_set_dials</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb83-3"><a href="support-vector-machine-svm-svr.html#cb83-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(</span>
<span id="cb83-4"><a href="support-vector-machine-svm-svr.html#cb83-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">cost =</span> <span class="fu">cost</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>)),</span>
<span id="cb83-5"><a href="support-vector-machine-svm-svr.html#cb83-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">rbf_sigma =</span> <span class="fu">rbf_sigma</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>)), </span>
<span id="cb83-6"><a href="support-vector-machine-svm-svr.html#cb83-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">margin =</span> <span class="fu">svm_margin</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb83-7"><a href="support-vector-machine-svm-svr.html#cb83-7" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb83-8"><a href="support-vector-machine-svm-svr.html#cb83-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-9"><a href="support-vector-machine-svm-svr.html#cb83-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb83-10"><a href="support-vector-machine-svm-svr.html#cb83-10" aria-hidden="true" tabindex="-1"></a>svm_class_grid <span class="ot">&lt;-</span> svm_class_parameters_set <span class="sc">%&gt;%</span> </span>
<span id="cb83-11"><a href="support-vector-machine-svm-svr.html#cb83-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grid_max_entropy</span>(<span class="at">size =</span> <span class="dv">100</span>)</span>
<span id="cb83-12"><a href="support-vector-machine-svm-svr.html#cb83-12" aria-hidden="true" tabindex="-1"></a>svm_class_grid</span></code></pre></div>
<pre><code>## # A tibble: 100 × 3
##     cost rbf_sigma margin
##    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;
##  1  1.22    0.504   0.571
##  2  1.41    1.22    0.329
##  3  1.33    0.111   1.38 
##  4  1.35    0.0935 -1.65 
##  5  1.04    0.937   1.48 
##  6  1.14    0.0154 -1.91 
##  7  1.39   70.2    -1.98 
##  8  1.07    1.16   -0.487
##  9  1.17    1.34    0.948
## 10  1.02    0.0303  0.230
## # … with 90 more rows</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="support-vector-machine-svm-svr.html#cb85-1" aria-hidden="true" tabindex="-1"></a>ctrl_grid <span class="ot">&lt;-</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> T, <span class="at">verbose =</span> T)</span></code></pre></div>
<p><strong>Paso 6: Entrenamiento de modelos con hiperparámetros definidos</strong></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="support-vector-machine-svm-svr.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb86-2"><a href="support-vector-machine-svm-svr.html#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="support-vector-machine-svm-svr.html#cb86-3" aria-hidden="true" tabindex="-1"></a>UseCores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb86-4"><a href="support-vector-machine-svm-svr.html#cb86-4" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(UseCores)</span>
<span id="cb86-5"><a href="support-vector-machine-svm-svr.html#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cluster)</span>
<span id="cb86-6"><a href="support-vector-machine-svm-svr.html#cb86-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-7"><a href="support-vector-machine-svm-svr.html#cb86-7" aria-hidden="true" tabindex="-1"></a>svm1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb86-8"><a href="support-vector-machine-svm-svr.html#cb86-8" aria-hidden="true" tabindex="-1"></a>svm_tune_class_result <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb86-9"><a href="support-vector-machine-svm-svr.html#cb86-9" aria-hidden="true" tabindex="-1"></a>  svm_class_workflow,</span>
<span id="cb86-10"><a href="support-vector-machine-svm-svr.html#cb86-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> telco_folds,</span>
<span id="cb86-11"><a href="support-vector-machine-svm-svr.html#cb86-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> svm_class_grid,</span>
<span id="cb86-12"><a href="support-vector-machine-svm-svr.html#cb86-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(roc_auc, pr_auc),</span>
<span id="cb86-13"><a href="support-vector-machine-svm-svr.html#cb86-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> ctrl_grid</span>
<span id="cb86-14"><a href="support-vector-machine-svm-svr.html#cb86-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb86-15"><a href="support-vector-machine-svm-svr.html#cb86-15" aria-hidden="true" tabindex="-1"></a>svm2 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); svm2 <span class="sc">-</span> svm1</span>
<span id="cb86-16"><a href="support-vector-machine-svm-svr.html#cb86-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-17"><a href="support-vector-machine-svm-svr.html#cb86-17" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cluster)</span>
<span id="cb86-18"><a href="support-vector-machine-svm-svr.html#cb86-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-19"><a href="support-vector-machine-svm-svr.html#cb86-19" aria-hidden="true" tabindex="-1"></a>svm_tune_class_result <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/svm_model_class.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="support-vector-machine-svm-svr.html#cb87-1" aria-hidden="true" tabindex="-1"></a>svm_tune_class_result <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/svm_model_class.rds&quot;</span>)</span>
<span id="cb87-2"><a href="support-vector-machine-svm-svr.html#cb87-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-3"><a href="support-vector-machine-svm-svr.html#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="fu">unnest</span>(svm_tune_class_result, .metrics)</span></code></pre></div>
<pre><code>## # A tibble: 1,966 × 11
##    splits             id      cost rbf_sigma margin .metric .estimator .estimate
##    &lt;list&gt;             &lt;chr&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
##  1 &lt;split [4437/493]&gt; Fold01  1.22    0.504   0.571 roc_auc binary         0.760
##  2 &lt;split [4437/493]&gt; Fold01  1.22    0.504   0.571 pr_auc  binary         0.854
##  3 &lt;split [4437/493]&gt; Fold01  1.41    1.22    0.329 roc_auc binary         0.735
##  4 &lt;split [4437/493]&gt; Fold01  1.41    1.22    0.329 pr_auc  binary         0.851
##  5 &lt;split [4437/493]&gt; Fold01  1.33    0.111   1.38  roc_auc binary         0.756
##  6 &lt;split [4437/493]&gt; Fold01  1.33    0.111   1.38  pr_auc  binary         0.859
##  7 &lt;split [4437/493]&gt; Fold01  1.35    0.0935 -1.65  roc_auc binary         0.762
##  8 &lt;split [4437/493]&gt; Fold01  1.35    0.0935 -1.65  pr_auc  binary         0.866
##  9 &lt;split [4437/493]&gt; Fold01  1.04    0.937   1.48  roc_auc binary         0.751
## 10 &lt;split [4437/493]&gt; Fold01  1.04    0.937   1.48  pr_auc  binary         0.859
## # … with 1,956 more rows, and 3 more variables: .config &lt;chr&gt;, .notes &lt;list&gt;,
## #   .predictions &lt;list&gt;</code></pre>
<p><strong>Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</strong></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="support-vector-machine-svm-svr.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(svm_tune_class_result)</span></code></pre></div>
<pre><code>## # A tibble: 200 × 9
##     cost rbf_sigma margin .metric .estimator  mean     n std_err .config        
##    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          
##  1  1.22    0.504   0.571 pr_auc  binary     0.867    10 0.00769 Preprocessor1_…
##  2  1.22    0.504   0.571 roc_auc binary     0.767    10 0.00534 Preprocessor1_…
##  3  1.41    1.22    0.329 pr_auc  binary     0.868    10 0.00710 Preprocessor1_…
##  4  1.41    1.22    0.329 roc_auc binary     0.764    10 0.00778 Preprocessor1_…
##  5  1.33    0.111   1.38  pr_auc  binary     0.878    10 0.00588 Preprocessor1_…
##  6  1.33    0.111   1.38  roc_auc binary     0.776    10 0.00505 Preprocessor1_…
##  7  1.35    0.0935 -1.65  pr_auc  binary     0.880    10 0.00569 Preprocessor1_…
##  8  1.35    0.0935 -1.65  roc_auc binary     0.779    10 0.00499 Preprocessor1_…
##  9  1.04    0.937   1.48  pr_auc  binary     0.871    10 0.00637 Preprocessor1_…
## 10  1.04    0.937   1.48  roc_auc binary     0.769    10 0.00654 Preprocessor1_…
## # … with 190 more rows</code></pre>
<p>En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="support-vector-machine-svm-svr.html#cb91-1" aria-hidden="true" tabindex="-1"></a>svm_tune_class_result <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="support-vector-machine-svm-svr.html#cb92-1" aria-hidden="true" tabindex="-1"></a>svm_tune_class_result <span class="sc">%&gt;%</span> <span class="fu">show_best</span>(<span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 9
##     cost rbf_sigma margin .metric .estimator  mean     n std_err .config        
##    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          
##  1  1.23   0.00686 -1.20  roc_auc binary     0.808     7 0.00593 Preprocessor1_…
##  2  1.02   0.0303   0.230 roc_auc binary     0.805     9 0.00529 Preprocessor1_…
##  3  1.05   0.00823  0.904 roc_auc binary     0.805     9 0.00624 Preprocessor1_…
##  4  1.14   0.0215   1.11  roc_auc binary     0.804    10 0.00505 Preprocessor1_…
##  5  1.14   0.0154  -1.91  roc_auc binary     0.803     8 0.00625 Preprocessor1_…
##  6  1.19   0.0306  -1.45  roc_auc binary     0.803    10 0.00517 Preprocessor1_…
##  7  1.06   0.0350  -1.54  roc_auc binary     0.803    10 0.00517 Preprocessor1_…
##  8  1.22   0.0360   0.552 roc_auc binary     0.803    10 0.00517 Preprocessor1_…
##  9  1.36   0.0368   0.596 roc_auc binary     0.803    10 0.00515 Preprocessor1_…
## 10  1.11   0.00676 -1.42  roc_auc binary     0.802     9 0.00670 Preprocessor1_…</code></pre>
<p><strong>Paso 8: Selección de modelo a usar</strong></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="support-vector-machine-svm-svr.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Selección del mejor modelo según la métrica ROC AUC</span></span>
<span id="cb94-2"><a href="support-vector-machine-svm-svr.html#cb94-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-3"><a href="support-vector-machine-svm-svr.html#cb94-3" aria-hidden="true" tabindex="-1"></a>svm_classification_best_model <span class="ot">&lt;-</span> <span class="fu">select_best</span>(svm_tune_class_result, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb94-4"><a href="support-vector-machine-svm-svr.html#cb94-4" aria-hidden="true" tabindex="-1"></a>svm_classification_best_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##    cost rbf_sigma margin .config               
##   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                 
## 1  1.23   0.00686  -1.20 Preprocessor1_Model043</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="support-vector-machine-svm-svr.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Selección del modelo más regularizado a menos de una desviación estandar, según la métrica ROC AUC</span></span>
<span id="cb96-2"><a href="support-vector-machine-svm-svr.html#cb96-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-3"><a href="support-vector-machine-svm-svr.html#cb96-3" aria-hidden="true" tabindex="-1"></a>svm_classification_best_1se_model <span class="ot">&lt;-</span> svm_tune_class_result <span class="sc">%&gt;%</span> </span>
<span id="cb96-4"><a href="support-vector-machine-svm-svr.html#cb96-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_by_one_std_err</span>(<span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>, <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb96-5"><a href="support-vector-machine-svm-svr.html#cb96-5" aria-hidden="true" tabindex="-1"></a>svm_classification_best_1se_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 11
##    cost rbf_sigma margin .metric .estimator  mean     n std_err .config    .best
##   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;
## 1  1.14    0.0154  -1.91 roc_auc binary     0.803     8 0.00625 Preproces… 0.808
## # … with 1 more variable: .bound &lt;dbl&gt;</code></pre>
<p><strong>Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</strong></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="support-vector-machine-svm-svr.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Modelo final </span></span>
<span id="cb98-2"><a href="support-vector-machine-svm-svr.html#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1352</span>)</span>
<span id="cb98-3"><a href="support-vector-machine-svm-svr.html#cb98-3" aria-hidden="true" tabindex="-1"></a>svm_classification_final_model <span class="ot">&lt;-</span> svm_class_workflow <span class="sc">%&gt;%</span></span>
<span id="cb98-4"><a href="support-vector-machine-svm-svr.html#cb98-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(svm_classification_best_model) <span class="sc">%&gt;%</span></span>
<span id="cb98-5"><a href="support-vector-machine-svm-svr.html#cb98-5" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(<span class="at">data =</span> telco_train)</span>
<span id="cb98-6"><a href="support-vector-machine-svm-svr.html#cb98-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb98-7"><a href="support-vector-machine-svm-svr.html#cb98-7" aria-hidden="true" tabindex="-1"></a>svm_classification_final_model</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: svm_rbf()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 5 Recipe Steps
## 
## • step_num2factor()
## • step_normalize()
## • step_dummy()
## • step_impute_median()
## • step_rm()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Support Vector Machine object of class &quot;ksvm&quot; 
## 
## SV type: C-svc  (classification) 
##  parameter : cost C = 1.22744145128527 
## 
## Gaussian Radial Basis kernel function. 
##  Hyperparameter : sigma =  0.00685742851317484 
## 
## Number of Support Vectors : 2580 
## 
## Objective Function Value : -3090.757 
## Training error : 0.223327 
## Probability model included.</code></pre>
<p>Como hemos hablado anteriormente, este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.</p>
<p>Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos <a href="https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba">data leakage</a>. Para enfrentar esto, ayuda estimar y ordenar el valor de importancia del modelo.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="support-vector-machine-svm-svr.html#cb100-1" aria-hidden="true" tabindex="-1"></a>churn_importance <span class="ot">&lt;-</span> svm_classification_final_model <span class="sc">%&gt;%</span> </span>
<span id="cb100-2"><a href="support-vector-machine-svm-svr.html#cb100-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb100-3"><a href="support-vector-machine-svm-svr.html#cb100-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vi</span>(</span>
<span id="cb100-4"><a href="support-vector-machine-svm-svr.html#cb100-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;permute&quot;</span>,</span>
<span id="cb100-5"><a href="support-vector-machine-svm-svr.html#cb100-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">nsim =</span> <span class="dv">10</span>,</span>
<span id="cb100-6"><a href="support-vector-machine-svm-svr.html#cb100-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">target =</span> <span class="st">&quot;Churn&quot;</span>,</span>
<span id="cb100-7"><a href="support-vector-machine-svm-svr.html#cb100-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">metric =</span> <span class="st">&quot;auc&quot;</span>,</span>
<span id="cb100-8"><a href="support-vector-machine-svm-svr.html#cb100-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">reference_class =</span> <span class="st">&quot;Yes&quot;</span>,</span>
<span id="cb100-9"><a href="support-vector-machine-svm-svr.html#cb100-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">pred_wrapper =</span> kernlab<span class="sc">::</span>predict, </span>
<span id="cb100-10"><a href="support-vector-machine-svm-svr.html#cb100-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">train =</span> <span class="fu">juice</span>(telco_rec)</span>
<span id="cb100-11"><a href="support-vector-machine-svm-svr.html#cb100-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb100-12"><a href="support-vector-machine-svm-svr.html#cb100-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-13"><a href="support-vector-machine-svm-svr.html#cb100-13" aria-hidden="true" tabindex="-1"></a>churn_importance <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/vip_telco_svm.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="support-vector-machine-svm-svr.html#cb101-1" aria-hidden="true" tabindex="-1"></a>churn_importance <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/vip_telco_svm.rds&quot;</span>)</span>
<span id="cb101-2"><a href="support-vector-machine-svm-svr.html#cb101-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-3"><a href="support-vector-machine-svm-svr.html#cb101-3" aria-hidden="true" tabindex="-1"></a>churn_importance</span></code></pre></div>
<pre><code>## # A tibble: 34 × 3
##    Variable          Importance   StDev
##    &lt;chr&gt;                  &lt;dbl&gt;   &lt;dbl&gt;
##  1 TotalCharges          0.0637 0.00487
##  2 MonthlyCharges        0.0539 0.00983
##  3 SeniorCitizen         0.0219 0.00515
##  4 gender_Male           0      0      
##  5 Partner_Yes           0      0      
##  6 Dependents_Yes        0      0      
##  7 tenure_X1.2.years     0      0      
##  8 tenure_X2.3.years     0      0      
##  9 tenure_X3.4.years     0      0      
## 10 tenure_X4.5.years     0      0      
## # … with 24 more rows</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="support-vector-machine-svm-svr.html#cb103-1" aria-hidden="true" tabindex="-1"></a>churn_importance <span class="sc">%&gt;%</span></span>
<span id="cb103-2"><a href="support-vector-machine-svm-svr.html#cb103-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Variable =</span> <span class="fu">fct_reorder</span>(Variable, Importance)) <span class="sc">%&gt;%</span></span>
<span id="cb103-3"><a href="support-vector-machine-svm-svr.html#cb103-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(Importance, Variable, <span class="at">color =</span> Variable)) <span class="sc">+</span></span>
<span id="cb103-4"><a href="support-vector-machine-svm-svr.html#cb103-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">xmin =</span> Importance <span class="sc">-</span> StDev, <span class="at">xmax =</span> Importance <span class="sc">+</span> StDev),</span>
<span id="cb103-5"><a href="support-vector-machine-svm-svr.html#cb103-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">size =</span> <span class="fl">1.3</span>) <span class="sc">+</span></span>
<span id="cb103-6"><a href="support-vector-machine-svm-svr.html#cb103-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb103-7"><a href="support-vector-machine-svm-svr.html#cb103-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="sc">+</span></span>
<span id="cb103-8"><a href="support-vector-machine-svm-svr.html#cb103-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Variable Importance Measure&quot;</span>)</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p><strong>Paso 10: Validar poder predictivo con datos de prueba</strong></p>
<p>Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="support-vector-machine-svm-svr.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicciones</span></span>
<span id="cb104-2"><a href="support-vector-machine-svm-svr.html#cb104-2" aria-hidden="true" tabindex="-1"></a>telco_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(telco_split)</span>
<span id="cb104-3"><a href="support-vector-machine-svm-svr.html#cb104-3" aria-hidden="true" tabindex="-1"></a>results_cla <span class="ot">&lt;-</span> <span class="fu">predict</span>(svm_classification_final_model, telco_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb104-4"><a href="support-vector-machine-svm-svr.html#cb104-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">bind_cols</span>(<span class="at">truth =</span> telco_test<span class="sc">$</span>Churn) <span class="sc">%&gt;%</span> </span>
<span id="cb104-5"><a href="support-vector-machine-svm-svr.html#cb104-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">truth =</span> <span class="fu">factor</span>(truth, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&#39;No&#39;</span>, <span class="st">&#39;Yes&#39;</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&#39;No&#39;</span>, <span class="st">&#39;Yes&#39;</span>)))</span>
<span id="cb104-6"><a href="support-vector-machine-svm-svr.html#cb104-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-7"><a href="support-vector-machine-svm-svr.html#cb104-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results_cla)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##   .pred_No .pred_Yes truth
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;
## 1    0.854    0.146  No   
## 2    0.247    0.753  Yes  
## 3    0.822    0.178  No   
## 4    0.871    0.129  No   
## 5    0.923    0.0771 No   
## 6    0.547    0.453  No</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="support-vector-machine-svm-svr.html#cb106-1" aria-hidden="true" tabindex="-1"></a>roc_curve_data <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(</span>
<span id="cb106-2"><a href="support-vector-machine-svm-svr.html#cb106-2" aria-hidden="true" tabindex="-1"></a>  results_cla, </span>
<span id="cb106-3"><a href="support-vector-machine-svm-svr.html#cb106-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> truth, </span>
<span id="cb106-4"><a href="support-vector-machine-svm-svr.html#cb106-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_Yes, </span>
<span id="cb106-5"><a href="support-vector-machine-svm-svr.html#cb106-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span></span>
<span id="cb106-6"><a href="support-vector-machine-svm-svr.html#cb106-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb106-7"><a href="support-vector-machine-svm-svr.html#cb106-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-8"><a href="support-vector-machine-svm-svr.html#cb106-8" aria-hidden="true" tabindex="-1"></a>roc_curve_data</span></code></pre></div>
<pre><code>## # A tibble: 2,083 × 3
##    .threshold specificity sensitivity
##         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1  -Inf         0              1    
##  2     0.0331    0              1    
##  3     0.0339    0.000646       1    
##  4     0.0339    0.00129        1    
##  5     0.0340    0.00194        1    
##  6     0.0348    0.00259        1    
##  7     0.0349    0.00323        1    
##  8     0.0356    0.00323        0.998
##  9     0.0357    0.00388        0.998
## 10     0.0361    0.00452        0.998
## # … with 2,073 more rows</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="support-vector-machine-svm-svr.html#cb108-1" aria-hidden="true" tabindex="-1"></a>roc_curve_plot <span class="ot">&lt;-</span> roc_curve_data <span class="sc">%&gt;%</span> </span>
<span id="cb108-2"><a href="support-vector-machine-svm-svr.html#cb108-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity)) <span class="sc">+</span></span>
<span id="cb108-3"><a href="support-vector-machine-svm-svr.html#cb108-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">colour =</span> <span class="st">&#39;lightblue&#39;</span>) <span class="sc">+</span></span>
<span id="cb108-4"><a href="support-vector-machine-svm-svr.html#cb108-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>() <span class="sc">+</span></span>
<span id="cb108-5"><a href="support-vector-machine-svm-svr.html#cb108-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb108-6"><a href="support-vector-machine-svm-svr.html#cb108-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROC Curve&quot;</span>)<span class="sc">+</span></span>
<span id="cb108-7"><a href="support-vector-machine-svm-svr.html#cb108-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb108-8"><a href="support-vector-machine-svm-svr.html#cb108-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-9"><a href="support-vector-machine-svm-svr.html#cb108-9" aria-hidden="true" tabindex="-1"></a>roc_curve_plot</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="support-vector-machine-svm-svr.html#cb109-1" aria-hidden="true" tabindex="-1"></a>pr_curve_data <span class="ot">&lt;-</span> <span class="fu">pr_curve</span>(</span>
<span id="cb109-2"><a href="support-vector-machine-svm-svr.html#cb109-2" aria-hidden="true" tabindex="-1"></a>  results_cla, </span>
<span id="cb109-3"><a href="support-vector-machine-svm-svr.html#cb109-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> truth, </span>
<span id="cb109-4"><a href="support-vector-machine-svm-svr.html#cb109-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_Yes, </span>
<span id="cb109-5"><a href="support-vector-machine-svm-svr.html#cb109-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">event_level =</span> <span class="st">&#39;second&#39;</span></span>
<span id="cb109-6"><a href="support-vector-machine-svm-svr.html#cb109-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb109-7"><a href="support-vector-machine-svm-svr.html#cb109-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-8"><a href="support-vector-machine-svm-svr.html#cb109-8" aria-hidden="true" tabindex="-1"></a>pr_curve_data</span></code></pre></div>
<pre><code>## # A tibble: 2,082 × 3
##    .threshold  recall precision
##         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;
##  1    Inf     0           1    
##  2      0.964 0.00177     1    
##  3      0.946 0.00353     1    
##  4      0.946 0.00530     1    
##  5      0.929 0.00707     1    
##  6      0.921 0.00707     0.8  
##  7      0.918 0.00883     0.833
##  8      0.918 0.0106      0.857
##  9      0.915 0.0124      0.875
## 10      0.908 0.0141      0.889
## # … with 2,072 more rows</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="support-vector-machine-svm-svr.html#cb111-1" aria-hidden="true" tabindex="-1"></a>pr_curve_plot <span class="ot">&lt;-</span> pr_curve_data <span class="sc">%&gt;%</span> </span>
<span id="cb111-2"><a href="support-vector-machine-svm-svr.html#cb111-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> recall, <span class="at">y =</span> precision)) <span class="sc">+</span></span>
<span id="cb111-3"><a href="support-vector-machine-svm-svr.html#cb111-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">colour =</span> <span class="st">&#39;lightblue&#39;</span>) <span class="sc">+</span></span>
<span id="cb111-4"><a href="support-vector-machine-svm-svr.html#cb111-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb111-5"><a href="support-vector-machine-svm-svr.html#cb111-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Precision vs Recall&quot;</span>)<span class="sc">+</span></span>
<span id="cb111-6"><a href="support-vector-machine-svm-svr.html#cb111-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb111-7"><a href="support-vector-machine-svm-svr.html#cb111-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-8"><a href="support-vector-machine-svm-svr.html#cb111-8" aria-hidden="true" tabindex="-1"></a>pr_curve_plot</span></code></pre></div>
<p><img src="amt22_03intro2mls2_files/figure-html/unnamed-chunk-81-2.png" width="672" /></p>
<p>Pueden usar la app de <a href="https://acturio.shinyapps.io/confusion_matrix/?_ga=2.157345976.322506426.1653670259-130075619.1646374742">shiny</a> que nos permite jugar con el treshold de clasificación para tomar la mejor decisión.</p>
</div>
</div>
<div id="ejercicios-1" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Ejercicios<a href="support-vector-machine-svm-svr.html#ejercicios-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Crear un workflow de principio a fin usando SVM con kernel lineal</p></li>
<li><p>Crear un workflow de principio a fin usando SVM con kernel polinomial</p></li>
<li><p>Crear un workflow de principio a fin usando SVR con kernel lineal</p></li>
<li><p>Crear un workflow de principio a fin usando SVR con kernel polinomial</p></li>
<li><p>Comparar resultados con ejercicio desarrollado en clase</p></li>
</ol>
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="feature-engineering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bagging-boosting.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["amt22_03intro2mls2.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
